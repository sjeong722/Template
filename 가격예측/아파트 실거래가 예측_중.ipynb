{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ba74d64",
   "metadata": {},
   "source": [
    "## ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ ì˜ˆì¸¡ í”„ë¡œì íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0e0330",
   "metadata": {},
   "source": [
    "## Stage 1. ë°ì´í„°í™•ì¸\n",
    "ë°ì´í„°ë¥¼ í™•ì¸í•´ ë³´ê³  ì–´ë–»ê²Œ ë¶„ì„í• ì§€ ê³„íší•´ ë´…ì‹œë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fbe1ed",
   "metadata": {},
   "source": [
    "### 1. ë°ì´í„° ë¶„ì„ ì „ ì¤€ë¹„\n",
    "[ë¬¸ì œ1]\n",
    "CSV íŒŒì¼ì„ ë°ì´í„°í”„ë ˆì„ í˜•ì‹ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f691f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255df7c0",
   "metadata": {},
   "source": [
    "### 2. ë°ì´í„° í™•ì¸\n",
    "[ë¬¸ì œ2]\n",
    "trainì˜ ì¸ë±ìŠ¤ ê¸°ì¤€ ìƒìœ„ 5ê°œ ë°ì´í„° í™•ì¸í•˜ê¸°.\n",
    "ê·¸ë¦¬ê³  ì•ìœ¼ë¡œ ì–´ë–»ê²Œ ë¶„ì„ì„ ì§„í–‰í• ì§€ ìƒê°í•´ë³´ê¸°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1134eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b3dbb1",
   "metadata": {},
   "source": [
    "### 3. ë°ì´í„° íƒ€ì… í™•ì¸\n",
    "í•™ìŠµ ë°ì´í„°ë¥¼ ì´ìš©í•´ì„œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµ ì‹œí‚¤ê¸° ìœ„í•´ì„œëŠ”,\n",
    "ë°ì´í„°ì˜ íƒ€ì…(Dtype)ì´ ê³„ì‚° ê°€ëŠ¥í•œ í˜•íƒœì—¬ì•¼ í•¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c092215",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c02966",
   "metadata": {},
   "source": [
    "### 4. ë°ì´í„° í†µê³„ê°’ í™•ì¸\n",
    "[ë¬¸ì œ3] describe() í•¨ìˆ˜ë¥¼ ì´ìš©í•´ ìˆ˜ì¹˜í˜• ë°ì´í„°ì˜ í†µê³„ê°’ì„ í™•ì¸í•´ë³´ê¸°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47840314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_int(string):\n",
    "    if type(string) == str:\n",
    "        string = string.replace(',','')\n",
    "        return int(string)\n",
    "    else:\n",
    "        return string\n",
    "\n",
    "train['transaction_real_price'] = train['transaction_real_price'].apply(str_to_int)\n",
    "\n",
    "columns = ['exclusive_use_area', 'floor', 'transaction_real_price']\n",
    "train[columns].describe()\n",
    "\n",
    "# í‰ê·  meanê°’ê³¼ í‘œì¤€í¸ì°¨ stdê°’ì„ í†µí•´ ê°€ê²© ë¶„í¬ í™•ì¸\n",
    "# 1ì‚¬ë¶„ìœ„ìˆ˜ 25% ê°’ê³¼ 2ì‚¬ë¶„ìœ„ìˆ˜ 50% ê°’ ì°¨ì´ê°€ ë¯¸ë¯¸í•œ ê²ƒìœ¼ë¡œ ë³´ì•„\n",
    "# exclusive_use_area ëŠ” ì¢ì€ ë²”ìœ„ì— ëª°ë ¤ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŒ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f84ab19",
   "metadata": {},
   "source": [
    "### 5. í…ŒìŠ¤íŠ¸ ë°ì´í„° í™•ì¸\n",
    "[ë¬¸ì œ4] \n",
    "testì˜ ì¸ë±ìŠ¤ ê¸°ì¤€ ìƒìœ„ 10ê°œ ë°ì´í„° í™•ì¸."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547e0943",
   "metadata": {},
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd8108e",
   "metadata": {},
   "source": [
    "### 6. ì œì¶œ ë°ì´í„° í™•ì¸\n",
    "[ë¬¸ì œ5]\n",
    "submissionì˜ ì¸ë±ìŠ¤ ê¸°ì¤€ ìƒìœ„ 10ê°œ ë°ì´í„° í™•ì¸. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643793f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d0cbae",
   "metadata": {},
   "source": [
    "### 7. íƒ€ê²Ÿì˜ í‰ê· ê°’ êµ¬í•˜ê¸°\n",
    "[ë¬¸ì œ6] \n",
    "ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ì˜ í‰ê·  ê°’ì„ êµ¬í•˜ê³ , ê·¸ ê°’ì„ submissionì— ì ìš©í•˜ê¸°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f4b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_int(string):\n",
    "    if type(string) == str:\n",
    "        string = string.replace(',','')\n",
    "        return int(string)\n",
    "    else:\n",
    "        return string\n",
    "\n",
    "train['transaction_real_price'] = train['transaction_real_price'].apply(str_to_int)\n",
    "\n",
    "mean_apt_price = round(train['transaction_real_price'].mean())\n",
    "submission['transaction_real_price'] = mean_apt_price\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e18842",
   "metadata": {},
   "source": [
    "### 8. ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "[ë¬¸ì œ7]\n",
    "ì˜ˆì¸¡ì„ ë‹´ì€ submissionì„ CSV íŒŒì¼ë¡œ ìƒì„±í•˜ì—¬ ì œì¶œí•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a557116",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a883bcd",
   "metadata": {},
   "source": [
    "## Stage2. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)\n",
    "ëª©í‘œ: ë°ì´í„° íƒìƒ‰ì„ í†µí•œ ë°ì´í„° ë¶„ì„ ë°©í–¥ ì„¤ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799780e4",
   "metadata": {},
   "source": [
    "### 1. ë°ì´í„° ë¶„ì„ ì „ ì¤€ë¹„\n",
    "[ë¬¸ì œ1]\n",
    "ë°ì´í„° ë¶„ì„ì„ ìœ„í•´ì„œëŠ”, ë¨¼ì € ë°ì´í„°ë¥¼ ë³¼ ìˆ˜ ìˆì–´ì•¼ í•¨.\n",
    "í•™ìŠµìš© ë°ì´í„°ë¥¼ ì½ì–´ì™€ì„œ train ë³€ìˆ˜ ì•ˆì— ë„£ê¸°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e790544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5ff843",
   "metadata": {},
   "source": [
    "### 2. íƒ€ê²Ÿ ë°ì´í„° ì‚´í´ë³´ê¸°\n",
    "[ë¬¸ì œ2] \n",
    "str_to_int í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ ìë£Œí˜•ì´ strë¡œ ë˜ì–´ìˆëŠ” 'transaction_real_price'ë°ì´í„°ë¥¼ intë¡œ ë³€ê²½í•˜ê¸°.\n",
    "ê·¸ë¦¬ê³  ìˆ«ì ì‚¬ì´ì— ë“¤ì–´ìˆëŠ” ','(ì½¤ë§ˆ) ì œê±°í•˜ê¸°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a567ded3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def str_to_int(string):\n",
    "    if type(string) == str;\n",
    "        string = string.replace(',','')\n",
    "        return int(string)\n",
    "    else: \n",
    "        return string\n",
    "train['transaction_real_price'] = train['transaction_real_price'].apply(str_to_int)\n",
    "data = train['transaction_real_price']\n",
    "\n",
    "# Seabornì„ ì‚¬ìš©í•˜ì—¬ íˆìŠ¤í† ê·¸ë¨ ê·¸ë¦¬ê¸°\n",
    "sns.histplot(data, color='skyblue')\n",
    "\n",
    "# ê·¸ë˜í”„ì— ì œëª©ê³¼ ì¶• ë ˆì´ë¸” ì¶”ê°€\n",
    "plt.title('ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ íˆìŠ¤í† ê·¸ë¨')\n",
    "plt.xlabel('ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€')\n",
    "plt.ylabel('ë¹ˆë„ìˆ˜')\n",
    "\n",
    "# ê·¸ë˜í”„ í‘œì‹œ\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d207d2",
   "metadata": {},
   "source": [
    "### 3. ì‹œêµ°êµ¬ ì»¬ëŸ¼ íƒìƒ‰\n",
    "[ë¬¸ì œ3]\n",
    "'Sigungu' í”¼ì²˜ì˜ ê°’ë“¤ì´ ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ë³´ê¸°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59f6c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Sigungu'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144c86f2",
   "metadata": {},
   "source": [
    "### 4. ì§€ë²ˆ ì»¬ëŸ¼ íƒìƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba7a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.['Jibun'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4c226e",
   "metadata": {},
   "source": [
    "### 5. apt ì»¬ëŸ¼ íƒìƒ‰(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f013592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ì•„íŒŒíŠ¸ ì¢…ë¥˜ ì´ ê°œìˆ˜', len(train['apt_name'].unique()))\n",
    "display(train['apt_name'].value_counts()[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287d189a",
   "metadata": {},
   "source": [
    "### 6. apt ì»¬ëŸ¼ íƒìƒ‰(2)\n",
    "[ë¬¸ì œ4] \n",
    "'apt_name'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ groupby ì—°ì‚°ì„ ì ìš©í•´ 'trasaction_real_price'ì˜ í‰ê· ê°’ êµ¬í•˜ê¸°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3610b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train[['apt_name', 'transaction_rea;_price']].groupby('apt_name').mean()\n",
    "\n",
    "# Seabornì„ ì‚¬ìš©í•˜ì—¬ íˆìŠ¤í† ê·¸ë¨ ê·¸ë¦¬ê¸°\n",
    "sns.histplot(data, color='skyblue')\n",
    "\n",
    "# ê·¸ë˜í”„ì— ì œëª©ê³¼ ì¶• ë ˆì´ë¸” ì¶”ê°€\n",
    "plt.title('ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ íˆìŠ¤í† ê·¸ë¨')\n",
    "plt.xlabel('ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€')\n",
    "plt.ylabel('ì•„íŒŒíŠ¸ ìˆ˜')\n",
    "\n",
    "# ê·¸ë˜í”„ í‘œì‹œ\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3a289d",
   "metadata": {},
   "source": [
    "### 7. exclusive_use_area ì»¬ëŸ¼ íƒìƒ‰(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2938b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train['exclusive_use_area']\n",
    "\n",
    "num_bins = 30 # êµ¬ê°„ì˜ ê°œìˆ˜\n",
    "\n",
    "plt.figure(figsize=(18,4))\n",
    "sns.histplot(data, color='skyblue', bins=num_bins)\n",
    "\n",
    "plt.title('ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ íˆìŠ¤í† ê·¸ë¨')\n",
    "plt.xlabel('ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€')\n",
    "plt.ylabel('ë¹ˆë„ìˆ˜')\n",
    "\n",
    "x_ticks = [min(data) + i * (max(data) - min(data))/num_bins for i in range(num_bins + 1)]\n",
    "plt.xticks(x_ticks)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# binsëŠ” íˆìŠ¤í† ê·¸ë¨ì„ ë§Œë“¤ ë•Œ, ë°ì´í„°ë¥¼ ëª‡ê°œì˜ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆŒì§€ë¥¼ ì§€ì •í•˜ëŠ” íŒŒë¼ë¯¸í„°.\n",
    "\n",
    "# ê²°ê³¼í•´ì„\n",
    "# 58~96 ì œê³±ë¯¸í„° ë„“ì´ì˜ ì§‘ì˜ ê±°ë˜ëŸ‰ì´ ê°€ì¥ ë§ì€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŒ.\n",
    "# ê·¸ë¦¬ê³  íƒ€ê²Ÿ ë°ì´í„°ì™€ ë§ˆì°¬ê°€ì§€ë¡œ ì™¼ìª½ìœ¼ë¡œ ê·¸ë˜í”„ê°€ ì ë ¤ìˆëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì–´,\n",
    "# ë‘ ê°’ì´ ìƒê´€ê´€ê³„ê°€ ë†’ì€ì§€ í™•ì¸í•´ë³¼ í•„ìš”ê°€ ìˆì–´ ë³´ì„. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0582b6dd",
   "metadata": {},
   "source": [
    "### 8. exclusive_use_area ì»¬ëŸ¼ íƒìƒ‰(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25770877",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train['exclusive_use_area']\n",
    "\n",
    "num_bins = 10 # êµ¬ê°„ì˜ ê°œìˆ˜\n",
    "\n",
    "plt.figure(figsize=(18,4))\n",
    "sns.histplot(data, color='skyblue', bins=num_bins)\n",
    "\n",
    "plt.title('ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ íˆìŠ¤í† ê·¸ë¨')\n",
    "plt.xlabel('ì „ìš©ë©´ì ')\n",
    "plt.ylabel('ë¹ˆë„ìˆ˜')\n",
    "\n",
    "x_ticks = [min(data) + i * (max(data) - min(data) / num_bins for i in range(num_bins + 1 )]\n",
    "plt.xticks(x_ticks)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# x_ticksëŠ” ì „ìš©ë©´ì  ìµœì†Œ~ìµœëŒ€ ë²”ìœ„ë¥¼ 10ë“±ë¶„í–ˆì„ ë•Œì˜ ê²½ê³„ê°’ ëª©ë¡ì´ë©°, \n",
    "# plt.xticks(x_ticks)ë¡œ ê·¸ ì§€ì ì— xì¶• ëˆˆê¸ˆì„ í‘œì‹œí•˜ëŠ” ì—­í• ì„ í•¨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44383645",
   "metadata": {},
   "source": [
    "### 9. year_of_completion ì»¬ëŸ¼ íƒìƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8decc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_yearly = train.groupby(train['year_of_completion'])['transaction_real_price'].mean()\n",
    "\n",
    "plt.plot(train_yearly.index, train_yearly.values)\n",
    "plt.Xlabel('ì—°ë„')\n",
    "plt.ylabel('ê°€ê²©')\n",
    "plt.title('ì—°ë„ë³„ ì•„íŒŒíŠ¸ ê°€ê²©')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ê²°ê³¼í•´ì„\n",
    "# ì¤€ê³µë…„ë„ëŠ” 1979ë…„ë¶€í„° 2017ë…„ê¹Œì§€ ë‹¤ì–‘í•œ ì•„íŒŒíŠ¸ë“¤ì´ ì¡´ì¬.\n",
    "# ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ë¥¸ ì¡°ê±´ì´ ë™ì¼í•˜ë‹¤ë©´, ì˜¤ë˜ëœ ì•„íŒŒíŠ¸ëŠ” ìƒˆ ì•„íŒŒíŠ¸ì— ë¹„í•´ ê°€ê²©ì´ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ìŒ.\n",
    "# í•˜ì§€ë§Œ ì¶œë ¥ëœ ê·¸ë˜í”„ë¥¼ ë³´ë©´ ì•„íŒŒíŠ¸ ê°€ê²©ì— ë‹¤ë¥¸ ìš”ì¸ë“¤ì´ ë” í° ì˜í–¥ì„ ë¯¸ì¹˜ê¸° ë•Œë¬¸ì— \n",
    "# ì¤€ê³µë…„ë„ì˜ ê²½í–¥ì„±ìœ¼ ì°¾ê¸° ì–´ë ¤ì›Œë³´ì„.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca8d58f",
   "metadata": {},
   "source": [
    "### 10. ë‚ ì§œ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "[ë¬¸ì œ5]\n",
    "'transaction_day'í”¼ì²˜ì™€ 'transaction_date'í”¼ì²˜ë¥¼ í•©ì¹˜ê³ , ë°ì´í„°ì˜ í˜•ì‹ì„ datetimeìœ¼ë¡œ ë³€ê²½í•˜ê¸°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08647c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tran_data(x):\n",
    "    if type(x) == int:\n",
    "        if x < 10:\n",
    "            return '0'+str(x)\n",
    "        else:\n",
    "            return str(x)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "train['transaction_day'] = train['transaction_day'].apply(preprocess_tran_date)\n",
    "train['transaction_date'] = train['transaction_year_month'].astype(int).astype(str) + train['transaction_day'].astype(str)\n",
    "train['transaction_date'] = pd.to_datetime(train['transaction_date'])\n",
    "train = train.sort_values('transaction_date').reset_index(drop=True) \n",
    "\n",
    "# astype()ì€ ì§€ì •í•œ ë°ì´í„° íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë©”ì„œë“œ.\n",
    "# ì˜ˆë¥¼ ë“¤ì–´, df['col'] = df['col'].astype('float32')ëŠ” 'col' ì—´ì˜ ë°ì´í„° íƒ€ì…ì„ float32ë¡œ ë³€í™˜."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98fc422",
   "metadata": {},
   "source": [
    "### 11. ë‚ ì§œë³„ íƒ€ê²Ÿ ë°ì´í„° ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577f5543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Scatter Plot ê·¸ë¦¬ê¸°\n",
    "sns.regplot(\n",
    "        x=train['transaction_date'].map(mdates.date2num),\n",
    "        y=train['transaction_real_price'],\n",
    "        scatter_kws={'color': 'skyblue'},\n",
    "        line_kws={'color': 'red'}\n",
    ")\n",
    "\n",
    "# xì¶•ê³¼ yì¶• ë ˆì´ë¸” ì„¤ì •\n",
    "plt.xlabel('transaction_date')\n",
    "plt.ylabel('Price')\n",
    "\n",
    "# ê·¸ë˜í”„ ì œëª© ì„¤ì •\n",
    "plt.title('Scatter Plot of Price over Time')\n",
    "\n",
    "# ê·¸ë˜í”„ í‘œì‹œ\n",
    "plt.show()\n",
    "\n",
    "# ì„œìš¸ì˜ ì•„íŒŒíŠ¸ ê°€ê²©ì€ ê³¼ê±°ë¶€í„° ì§€ê¸ˆê¹Œì§€ ê¾¸ì¤€íˆ ì˜¤ë¥´ëŠ” ê²½í–¥ì„±ì´ ìˆëŠ”ë°,\n",
    "# ì •ë§ë¡œ ê·¸ëŸ¬í•œ ê²½í–¥ì´ ìˆëŠ”ì§€ í™•ì¸í•´ ë³´ê¸°.\n",
    "\n",
    "# ê·¸ë˜í”„ë¥¼ í™•ì¸í•´ ë³´ë©´, ì§ì„  í•˜ë‚˜ë¥¼ í™•ì¸ í•  ìˆ˜ ìˆìŒ.\n",
    "# ì§ì„ ì˜ ê¸°ìš¸ê¸°ê°€ ì–‘ìˆ˜ì´ë¯€ë¡œ, ë‚ ì§œì™€ ê°€ê²© ì‚¬ì´ì— ì–‘ì˜ ìƒê´€ê´€ê³„ê°€ ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŒ. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ae07f4",
   "metadata": {},
   "source": [
    "### 12. floor ë°ì´í„° íƒìƒ‰ \n",
    "[ë¬¸ì œ6]\n",
    "ë¹ˆì¹¸ì„ ì±„ì›Œ 'floor'ê°€ 1ì¼ë•Œì™€ 1ì´ ì•„ë‹ë•Œì˜ ì•„íŒŒíŠ¸ ì‹œê±°ë˜ê°€ í‰ê· ì„ êµ¬í•´ë³´ì. \n",
    "ë‹¨, 'sigungu'ëŠ” 'ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ ëŒ€ì¹˜ë™'ì´ë©°, 'exclusive_use_area'ëŠ” 60ë³´ë‹¤ í° ê²½ìš°ë§Œ ê³„ì‚°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3fa445",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_floor = train['floor'] == 1\n",
    "daechi = train['sigungu'] == 'ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ ëŒ€ì¹˜ë™'\n",
    "area_above_60 = train['exclusive_use_area'] > 60 \n",
    "\n",
    "print('1ì¸µ ì´ìƒ: ', train[one_floor & daechi & area_above_60].transaction_real_price.mean())\n",
    "print('2ì¸µ ì´ìƒ: ', train[~one_floor & daechi & area_above_60].transaction_real_price.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed58cb8",
   "metadata": {},
   "source": [
    "## Stage3. ë°ì´í„° ì „ì²˜ë¦¬(1)\n",
    "ë‚ ì§œ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ê³ , ì´ë¥¼ ì´ìš©í•´ ì•„íŒŒíŠ¸ ê°€ê²©ì„ ì˜ˆì¸¡í•˜ëŠ”ë° í•µì‹¬ì´ ë˜ëŠ” ë°ì´í„°ë“¤ì„ ì¶”ê°€í•˜ê¸°.\n",
    "íŠ¹íˆ ì•„íŒŒíŠ¸ ê°€ê²©ì€ ê¸ˆë¦¬ì— ì˜í–¥ì„ ë°›ëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆì–´ ì´ëŸ¬í•œ ë°ì´í„°ë¥¼ ì¶”ê°€í•´ì£¼ë©´ ì˜ˆì¸¡ì— ë„ì›€ì´ ë¨.\n",
    "ì¶”ê°€ì ìœ¼ë¡œ, ìµœê·¼ì— ê±°ë˜ëœ ê°€ê²©ì„ ì¶”ê°€í•´ ë³´ëŠ” ë“± ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ë‚ ì§œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ ì¤‘ìš”í•œ í”¼ì²˜ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŒ. \n",
    "\n",
    "ëª©í‘œ\n",
    "- ë‚ ì§œ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "- ë‚ ì§œì™€ Joiní•  ìˆ˜ ìˆëŠ” ë°ì´í„° ì¶”ê°€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c575cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8f6f0b3",
   "metadata": {},
   "source": [
    "### 1. ë°ì´í„° ì½ì–´ì˜¤ê¸°\n",
    "[ë¬¸ì œ1]\n",
    "ë¹ˆì¹¸ì„ ì±„ì›Œ trainê³¼ testë¥¼ í•˜ë‚˜ì˜ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í•©ì³ ë´…ì‹œë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbbb9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None # ê²½ê³  ë©”ì‹œì§€ ë„ê¸° # ë‘ê°œì˜ ë°ì´í„°ë¥¼ í•©ì¹˜ë©´ ì¸ë±ìŠ¤ ì¤‘ë³µìœ¼ë¡œ ì¸í•´ ê²½ê³  ë©”ì‹œì§€ ëœ¸.\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "interest_rate = pd.read_csv('interest_rate.csv') # í•œêµ­ì€í–‰ ê¸°ì¤€ê¸ˆë¦¬ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "train['train_test'] = 'train'\n",
    "test['train_test'] = 'test' \n",
    "all_data = pd.concat([train, test])\n",
    "all_data = all.data.reset_index(drop=True) # ì¸ë±ìŠ¤ ì¬ì„¤ì • # ë‘ ë°ì´í„°ë¥¼ í•©ì¹œ í›„ ì¸ë±ìŠ¤ê°€ ì¤‘ë³µë˜ë¯€ë¡œ ì´ˆê¸°í™” ì„¤ì • \n",
    "\n",
    "train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa383cd",
   "metadata": {},
   "source": [
    "### 2. ë‚ ì§œ ë°ì´í„°\n",
    "[ë¬¸ì œ2]\n",
    "ë‚ ì§œ ê´€ë ¨ ë°ì´í„°ê°€ 'transaction_year_month', 'transaction_day'ë¡œ ë¶„ë¦¬ë˜ì–´ ìˆëŠ”ë°, \n",
    "'transaction_date'ì— í•©ì³ í•˜ë‚˜ì˜ í”¼ì³ë¡œ ë§Œë“¤ì–´ ë´…ì‹œë‹¤. \n",
    "í•˜ë‚˜ë¡œ í•©ì³ì§„ 'transaction_date'ëŠ” yyyymmddí˜•ì‹ì˜ ë¬¸ìì—´(str)ë¡œ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤. \n",
    "ì˜ˆë¥¼ ë“¤ì–´ '20240101'ê³¼ ê°™ì´ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤. \n",
    "\n",
    "ê·¸ë¦¬ê³  ë‚˜ì„œ 'transaction_date'ë¥¼ to_datetime()í•¨ìˆ˜ë¥¼ ì´ìš©í•´ datetime í˜•íƒœë¡œ ë§Œë“¤ì–´ ì¤ì‹œë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb9dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒíŠ¸ 'transaction_day' í”¼ì²˜ê°€ 10ë³´ë‹¤ ì‘ì€ ê²½ìš°ì—ëŠ” ì•ì— ìˆ«ì '0' ë¶™ì´ê¸°\n",
    "# ë°ì´í„°í”„ë ˆì„ì—ì„œ ë§ì…ˆì—°ì‚°ì„ ì´ìš©í•˜ë©´ ë¬¸ìì—´ì„ ì—°ê²°í•  ìˆ˜ ìˆìŒ\n",
    "# datetimeì€ ë§ì…ˆ, ëº„ì…ˆ ë° ë¹„êµ ì—°ì‚°ì´ ê°€ëŠ¥í•˜ê¸° ë•Œë¬¸ì— ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ë‹¤ë£° ë•Œ í¸ë¦¬í•¨. ì—°,ì›”,ì¼ ë¶€ë¶„ ì •ë³´ ì¶”ì¶œë„ ê°€ëŠ¥.\n",
    "# datetimeí˜•íƒœë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ pandasì˜ to_datetime()í•¨ìˆ˜ ì‚¬ìš©\n",
    "\n",
    "\n",
    "def preprocess_tran_date(x):\n",
    "    ''' \n",
    "    ì •ìˆ˜í˜• ë³€ìˆ˜ì¸ transaction_day í”¼ì²˜ë¥¼ ì „ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ \n",
    "    '''\n",
    "    return  f\"{int(x):02d}\"  # xë¥¼ ì •ìˆ˜(int)ë¡œ ë³€í™˜ : ë¹ˆìë¦¬ëŠ” 0ìœ¼ë¡œ ì±„ìš°ê³  ë‘ ìë¦¿ìˆ˜ì˜ ì •ìˆ˜ë¡œ(decimal) í¬ë§·.\n",
    "\n",
    "# 1. ì¼(day) ë‘ ìë¦¬ ë¬¸ìì—´ë¡œ ë³€í™˜    \n",
    "all_data['transaction_day'] = all_data['transaction_day'].apply(preprocess_tran_date)\n",
    "\n",
    "# 2. ì—°ì›” + ì¼ ê²°í•© â†’ '20240105' í˜•ì‹\n",
    "all_data['transaction_date'] = all_data['transaction_year_month'].astype(int).astype(str) + all_data['transaction_day'].astype(str)\n",
    "# transaction_year_month ì»¬ëŸ¼(ì˜ˆ:\"202401\")ì„ astype(int) ì •ìˆ˜ë¡œ ë°”ê¿¨ë‹¤ê°€ astype(str)ë¬¸ìë¡œ ë°”ê¾¸ê¸°. ì™œëƒí•˜ë©´ ë°”ë¡œ strë¡œ ë°”ê¾¸ë©´ nanê°’ ìƒê²¨ì„œ ê¹¨ì§ˆ ìˆ˜ ìˆê¸° ë•Œë¬¸. \n",
    "# ê·¸ë‹¤ìŒ transaction_day ì»¬ëŸ¼(ì˜ˆ:\"5\")ì„ astype(str) ë¬¸ìì—´ë¡œ ë³€í™˜. ìœ„ f\"{int(x):02d}\" í•¨ìˆ˜ë¡œ \"05\" ë¼ëŠ” ë‘ìë¦¿ìˆ˜ ë§ì¶°ì§„ ìƒíƒœ.\n",
    "# + ë¡œ í•©ì³ì„œ ê²°ê³¼ì ìœ¼ë¡œ \"20240105\" ë¼ëŠ” ë¬¸ìì—´ë¡œ ë§ì¶¤. \n",
    "\n",
    "# 3. ë¬¸ìì—´ ë‚ ì§œ â†’ datetime í˜•ì‹\n",
    "all_data['transaction_date'] = pd.to_datetime(all_data['transaction_date']) \n",
    "# pd.to_datetime ìœ¼ë¡œ ë¬¸ìí˜•(str) \"20240105\"ë¥¼ ì§„ì§œ ë‚ ì§œí˜•(datetime64)ë¡œ ë³€ê²½ => ë‚ ì§œ ê³„ì‚°, ì‹œê³„ì—´ ì •ë ¬, ì›”ì—°ë„ ì¶”ì¶œ ê°€ëŠ¥í•˜ë„ë¡.\n",
    "\n",
    "# 4. ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬ + ì¸ë±ìŠ¤ ì´ˆê¸°í™”\n",
    "all_data = all_data.sort_values('transaction_date').reset_index(drop=True)\n",
    "# sort_value: ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬. ë‚´ë¦¼ì°¨ìˆœì€ ('ì»¬ëŸ¼ëª…', ascending=False) \n",
    "# # ì»¬ëŸ¼ë³„ë¡œ ì˜¤ë¦„, ë‚´ë¦¼ì°¨ìˆœ ì§€ì •í•˜ê³  ì‹¶ì„ ë–„ : sort_values(by=['ì»¬ëŸ¼1', 'ì»¬ëŸ¼2'],ascending=[False, True]) \n",
    "# reset_index: ì¸ë±ìŠ¤ë¥¼ ë‹¤ì‹œ 0ë¶€í„° ìˆœì„œëŒ€ë¡œ ì´ˆê¸°í™”. \n",
    "# drop=True: ê¸°ì¡´ ì¸ë±ìŠ¤ëŠ” ë²„ë¦¼. (drop=Falseë©´ ê¸°ì¡´ ì¸ë±ìŠ¤ ì˜†ì— ìƒˆë¡œ ìƒì„±ë¨)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0311ef",
   "metadata": {},
   "source": [
    "### 3. ì•„íŒŒíŠ¸ í‚¤ê°’ ìƒì„±\n",
    "[ë¬¸ì œ3]\n",
    "ngroup() í•¨ìˆ˜ë¥¼ ì´ìš©í•´ 'sigungu','apt_name'ì„ ì´ìš©í•œ ê·¸ë£¹ë³„ ì¸ë±ìŠ¤ ë§Œë“¤ì–´ ë´…ì‹œë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3103b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ì‹œêµ°êµ¬+ì•„íŒŒíŠ¸ëª…' ì¡°í•©ë³„ ê³ ìœ ë²ˆí˜¸(=ì•„íŒŒíŠ¸ ID)ì„ ìƒˆë¡œìš´ ì»¬ëŸ¼ìœ¼ë¡œ ìƒì„±í•˜ê¸°\n",
    "all_data['apartment_id'] = all_data.groupby(['sigungu','apt_name']).nroup()\n",
    "all_data['apartment_id'] \n",
    "\n",
    "# all_data.groupby(['sigungu','apt_name']): ('ê°•ë‚¨êµ¬','íìŠ¤í…Œì´íŠ¸') , ('ì„œì´ˆêµ¬', 'ë˜ë¯¸ì•ˆ')ìœ¼ë¡œ ê·¸ë£¹ ìƒì„±. \n",
    "# .ngroup(): ê° ê·¸ë£¹ì— ë²ˆí˜¸ ë§¤ê²¨ì£¼ëŠ” í•¨ìˆ˜. 0ë¶€í„° ì‹œì‘í•˜ëŠ” ì •ìˆ˜ IDë¥¼ ë¶€ì—¬. ì˜ˆ: ('ê°•ë‚¨êµ¬','íìŠ¤í…Œì´íŠ¸')= 0 , ('ì„œì´ˆêµ¬', 'ë˜ë¯¸ì•ˆ')= 1\n",
    "# all_data['apartment_id'] : 'apartment_id'ë¼ëŠ” ì´ë¦„ì˜ ì»¬ëŸ¼ìœ¼ë¡œ ì €ì¥í•˜ê¸°.\n",
    "# # ì´ë ‡ê²Œ ë§Œë“  apartment_idëŠ” ë‚˜ì¤‘ì— ê°™ì€ ì•„íŒŒíŠ¸ë³„ í‰ê· ê°€ê²©, ê±°ë˜íšŸìˆ˜ ì§‘ê³„ ë˜ëŠ” ëª¨ë¸ í•™ìŠµì‹œ ì•„íŒŒíŠ¸ë¥¼ ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜ë¡œ ì¸ì½”ë”©í•  ë•Œ ìœ ìš©í•¨. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfbe139",
   "metadata": {},
   "source": [
    "#### 4. ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65c7344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_int(string):\n",
    "    if type(string) == str:\n",
    "        string = string.replace(',','')\n",
    "        return int(string)\n",
    "    else:\n",
    "        return string \n",
    "    \n",
    "all_data['transaction_real_price'] = all_data['transaction_real_price'].apply(str_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401dc9f6",
   "metadata": {},
   "source": [
    "### 5. ì•„íŒŒíŠ¸ ë©´ì ìœ¼ë¡œ ë¶„ë¥˜í•˜ê¸°\n",
    "[ë¬¸ì œ4] 'exclusive_use_area' í”¼ì²˜ì—ì„œ íŒŒìƒëœ í”¼ì²˜ë¥¼ ë§Œë“¤ì–´ ë´…ì‹œë‹¤.\n",
    "'bucket_area'í”¼ì²˜ë¥¼ ìƒˆë¡œ ë§Œë“¤ì–´ 60 ë¯¸ë§Œì¸ ê²½ìš° 0, 85 ë¯¸ë§Œì¸ ê²½ìš° 1, ì´ì™¸ì—ëŠ” 2ë¥¼ ë„£ì–´ì¤ì‹œë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9618f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_area_bucket(area):\n",
    "    '''\n",
    "    exclusive_use_area(ì „ìš©ë©´ì )ì— ë”°ë¼ êµ¬ê°„(bucket)ì„ ë‚˜ëˆ„ëŠ” í•¨ìˆ˜\n",
    "    60 ë¯¸ë§Œ -> 0\n",
    "    85 ë¯¸ë§Œ -> 1\n",
    "    ê·¸ì™¸ -> 2\n",
    "    '''\n",
    "    \n",
    "    if area < 60:                              # areaëŠ” ì‹œë¦¬ì¦ˆê°€ ì „ì²´ê°€ ì•„ë‹ˆë¼ í•œ í–‰ì˜ ê°’ í•˜ë‚˜ì”©.\n",
    "    # if all_data['exclusive_use_area'] <= 60 : # ì´ë ‡ê²Œ ì“°ë©´ ì»¬ëŸ¼ ì „ì²´ë¥¼ ë¹„êµí•˜ë¼ëŠ” ëœ»ì„.\n",
    "        return 0 \n",
    "        # return all_data['bucket_area'] == 0   # == ë¹„êµ ì—°ì‚°ìëŠ” True/Falseë¥¼ ë°˜í™˜. \n",
    "    if area < 85 :\n",
    "        return 1\n",
    "    else :                                      # else ë’¤ì— : ì½œë¡  ë¹¼ë¨¹ì§€ ë§ê¸°. \n",
    "        return 2\n",
    "    \n",
    "# ê° í–‰ì˜ exclusive_use_area ê°’ì— í•¨ìˆ˜ ì ìš©\n",
    "all_data['bucket_area'] = all_data['exclusive_use_area'].apply(make_area_bucket)\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸ \n",
    "all_data[['exclusive_use_area','bucket_area']].head()\n",
    "\n",
    "# í•¨ìˆ˜ ì•ˆì—ì„œ all_dataë¥¼ ì°¸ì¡°í•  í•„ìš” ì—†ìŒ\n",
    "# applyëŠ” ê° ì›ì†Œ(=area ê°’)ì„ areaë¡œ ì „ë‹¬í•´ì£¼ê¸° ë•Œë¬¸ì—, í•¨ìˆ˜ ë‚´ë¶€ì—ì„œëŠ” all_data ì „ì²´ë¥¼ ì“¸ í•„ìš”ê°€ ì—†ë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da925303",
   "metadata": {},
   "source": [
    "### 6. ìµœê·¼ ì•„íŒŒíŠ¸ ê°€ê²© ë°ì´í„°\n",
    "[ë¬¸ì œ5]\n",
    "forë¬¸ì„ ì´ìš©í•´ ë°ì´í„°í”„ë ˆì„ì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ë ¤ê³  í•©ë‹ˆë‹¤.\n",
    "ë¹ˆì¹¸ì„ ì±„ì›Œ ë°˜ë³µë¬¸ì„ ì™„ì„±í•´ ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032aed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # ì§„í–‰ìƒí™©ì„ % ë¡œ ë³´ì—¬ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ \n",
    "from datetime import datetime \n",
    "\n",
    "def get_recent_price(all_data, idx, row):\n",
    "    # ì „ì²´ ë°ì´í„°ì—ì„œ, í˜„ì¬ ì¸ë±ìŠ¤ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí•œë‹¤.\n",
    "    temp_df = all_data.loc[:idx]\n",
    "    \n",
    "    # ì¶”ì¶œí•œ ë°ì´í„°ì—ì„œ, ê±°ë˜ë‚ ì§œê°€ rowê¸°ì¤€ìœ¼ë¡œ ê³¼ê±°ì´ê³  ë¹„ìŠ·í•œ ë©´ì ì¸ ì•„íŒŒíŠ¸ ê±°ë˜ë¥¼ ì¶”ì¶œ.\n",
    "    temp_df = temp_df[\n",
    "        (temp_df['transaction_date'] < row['transaction_date']) &\n",
    "        (temp_df['bucket_area'] == row['bucket_area'])\n",
    "    ]\n",
    "\n",
    "    # ë§Œì•½ ì¶”ì¶œí•œ ê²°ê³¼ê°€ ì•„ë¬´ê²ƒë„ ì—†ìœ¼ë©´, 2016-01-01 ì´ì „ ë°ì´í„°ì—ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œ.\n",
    "    if len(temp_df) == 0:\n",
    "        temp_df = all_data[\n",
    "         (all_data['transaction_date'] < datetime.strptime('2016-01-01', \"%Y-%m-%d\"))  \n",
    "         (all_data['bucket_area'] == row['bucket_area'])\n",
    "        ]\n",
    "        \n",
    "# datetime ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "# datetime.now() : í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ (ì—°ì›”ì¼ì‹œë¶„ì´ˆ) 2025-10-23-10-24-12\n",
    "# datetime.today() : ì˜¤ëŠ˜ ë‚ ì§œì™€ ì‹œê°„ now()ì™€ ë¹„ìŠ·\n",
    "# datetime.strptime(\"2024-01-05\",\"%Y-%m-%d\") \n",
    "    # strptime = string parse time : ë¬¸ìì—´ ì‹œê°„ì„ íŒŒì‹±(parse)í•´ì„œ datetime ê°ì²´ë¡œ ë³€í™˜í•œë‹¤. \n",
    "    # ë¬¸ìì—´ -> ë‚ ì§œë¡œ ë³€í™˜. \"2024-01-05\" -> datetime(2024,1,5)\n",
    "    \n",
    "# datetime.strftime(\"%Yë…„ %mì›” %dì¼\") \n",
    "    # strftime = string format time : ì‹œê°„ ë°ì´í„° datetime ê°ì²´ë¥¼ ì§€ì •í•œ í˜•ì‹(format)ì˜ ë¬¸ìì—´ë¡œ ë§Œë“ ë‹¤. \n",
    "    # ë‚ ì§œ -> ë¬¸ìì—´ë¡œ ë³€í™˜. \"2024ë…„ 01ì›” 05ì¼\"\n",
    "    \n",
    "# datetime.timedelta(days=7) : 7ì¼ ê°„ê²© ìƒì„±. ì˜¤ëŠ˜ë¶€í„° 7ì¼ í›„ì˜ ë‚ ì§œ -> today + timedelta(days=7) \n",
    "    \n",
    "    \n",
    "    # ì¶”ì¶œí•œ ë°ì´í„° ì¤‘, ê°™ì€ ì•„íŒŒíŠ¸ì¸ ê²½ìš° í•´ë‹¹ ê°’ì„ ì¶”ì¶œ.\n",
    "    recent_price = temp_df[(temp_df['apartment_id'] == row['apartment_id'])]\n",
    "\n",
    "    if len(recent_price) == 0:\n",
    "        # ë§Œì•½ ê°™ì€ ì´ë¦„ì˜ ì•„íŒŒíŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´, ê°™ì€ ì‹œê¶êµ¬ì— ìˆëŠ” ì•„íŒŒí‹‘ ì¶”ì¶œ.\n",
    "        recent_price = temp_df[(temp_df['sigungu'] == row['sigungu'])]\n",
    "        recent_price = recent_price.iloc[-1]['transaction_real_price']\n",
    "    else:\n",
    "         # ë§Œì•½ ê°™ì€ ì‹œêµ°êµ¬ì— ì•„íŒŒíŠ¸ ê±°ë˜ë‚´ì—­ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´, ê°€ì¥ ìµœê·¼ ê±°ë˜ë¥¼ ì‚¬ìš©.\n",
    "        recent_price = recent_price.iloc[-1]['transaction_rea_price'] \n",
    "    \n",
    "    # ê°€ì¥ ìµœê·¼ ê±°ë˜ê°€ ì—†ìœ¼ë©´ ì „ì²´ í‰ê· ì„ ì‚¬ìš©.\n",
    "    if recent_price is None:\n",
    "        recent_price = temp_df['transaction_real_price'].mean()\n",
    "    \n",
    "    return recent_price\n",
    "\n",
    "for idx, row in tqdm(all_data.iterrows(), total=all_data.shape[0]):  # iterrow()ëŠ” (idx, row)ë¥¼ ìŒìœ¼ë¡œ ë°˜ë³µ(iteration)í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë©”ì„œë“œ. \n",
    "    if row['train_test'] == 'test':\n",
    "        continue \n",
    "    all_data.loc[idx, 'recent_price'] = get_recent_price(all_data, idx, row)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd58b8ca",
   "metadata": {},
   "source": [
    "## 7. ì•„íŒŒíŠ¸ ìµœê·¼ ê±°ë˜ëŸ‰\n",
    "[ë¬¸ì œ6] ë¹ˆì¹¸ì„ ì±„ì›Œ, ê±°ë˜ì¼ì ê¸°ì¤€ìœ¼ë¡œ 90ì¼ ì´ì „ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c73531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta \n",
    "\n",
    "for idx, row in tqdm(all_date.iterrows(), total = all_data.shape[0]):\n",
    "    # transaction_dateê°€ 2014-03-30 ë‚ ì§œ ì´ì „ ë°ì´í„°ì¸ ê²½ìš°, 2014-03-30 ~ 2014-01-01 ë°ì´í„°ë¥¼ ì¶”ì¶œ.\n",
    "    if row['transaction_date'] <= datetime.strptime('2014-03-30', \"%Y-%m-%d\") : \n",
    "        start_day = datetime.strptime('2014-03-30', \"%Y-%m-%d\")\n",
    "        end_day = datetime.strptime('2014-01-01', \"%Y-%m-%d\")\n",
    "        cnt = len(all_data[(all_data['transaction_date'] >= start_day) & (all_data['transaction_date'] < end_Dat) & (all_date['sigungu'] == row['sigungu'])])\n",
    "    \n",
    "    # ê±°ë˜ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ 3ê°œì›” ì´ì „ ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ ë´…ì‹œë‹¤.\n",
    "    else:\n",
    "        start_day = row['transacction_date'] - timedelta(days=90)\n",
    "        end_day = row['transaction_date']\n",
    "        cnt = len(all_data[(all_data['transaction_date'] >= start_day) & (all_data['transaction_date'] < end_day) & (all_data['sigungu'] == row['sigungu'])])\n",
    "        \n",
    "    all_data.loc[idx, 'transaction_cnt'] = cnt \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8901d69",
   "metadata": {},
   "source": [
    "### 8. ê¸ˆë¦¬ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca97bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_rate = pd.read_csv('interest_rate.csv') # í•œêµ­ì€í–‰ ê¸°ì¤€ê¸ˆë¦¬ \n",
    "\n",
    "def make_date(row):\n",
    "    month_day = row['ì›”ì¼'].replace('ì›”','-')\n",
    "    month_dat = month_day.replace('dlf','')\n",
    "    date = str(row['ì—°ë„']) + '-' + month_day\n",
    "    return date\n",
    "\n",
    "interst_rate['ë‚ ì§œ'] = interst_rate.apply(lambda x: make_date(x), axis=1)\n",
    "interest_rate['ë‚ ì§œ'] = pd.to_datetime(interest_rate['ë‚ ì§œ'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6d59ba",
   "metadata": {},
   "source": [
    "### 9. ê¸ˆë¦¬ ë°ì´í„° ì ìš©í•˜ê¸°\n",
    "í•œêµ­ì€í–‰_ê¸°ì¤€ê¸ˆë¦¬.csv íŒŒì¼ì—ëŠ” ê¸ˆë¦¬ê°€ ë³€ë™ëœ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ê°€ ìŒ“ì—¬ ìˆê¸° ë•Œë¬¸ì—\n",
    "ì•„íŒŒíŠ¸ ë§¤ë§¤ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ìµœê·¼ ê°±ì‹ ëœ ê¸ˆë¦¬ë¥¼ ì ìš©í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9caf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in tqdm(all_data.iterrows(), total = all_data.shape[0]):\n",
    "    date = row['transaction_date']\n",
    "    rate = interest_rate[interest_rate['ë‚ ì§œ'] <= date].iloc[0]['ê¸ˆë¦¬']\n",
    "    # ê¸°ì¤€ê¸ˆë¦¬ ë°ì´í„°ì—ì„œ \"ê±°ë˜ì¼(date) ì´ì „ì˜ ê¸ˆë¦¬ë§Œ\" í•„í„°ë§í•´ì„œ interest_rateë¼ëŠ” ìƒˆë¡œìš´ df ìƒì„±.\n",
    "    # iloc[0] ê·¸ ê²°ê³¼ì—ì„œ ì²«ë²ˆì§¸ í–‰. ['ê¸ˆë¦¬'] ì»¬ëŸ¼ ê°’ ê°€ì ¸ì™€ë¼. \n",
    "    all_data.loc[idx, 'interest_rate'] = rate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb93a0",
   "metadata": {},
   "source": [
    "### 10. ì—°ì›” ë³€ìˆ˜ ì¶”ê°€\n",
    "ì—°ë„ë³„ ì›”ë³„ ì˜í–¥ì„ íŒŒì•…í•˜ê¸° ìœ„í•´ ë°ì´í„° ì¶”ê°€\n",
    "ì´ë¥¼ í†µí•´ ì—°ë„ë³„ ì „ì²´ì ì¸ ê²½í–¥ì„±ê³¼ ì›”ë³„ë¡œ ë°˜ë³µë˜ëŠ” ê²½í–¥ì„±ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f306f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['transaction_year'] = all_data['transaction_date'].dt.year  # dtëŠ” datetime64 í˜•ì‹ ë°ì´í„° accessor(ì ‘ê·¼ì) # ë‚ ì§œê°€ ë“¤ì–´ìˆëŠ” ì»¬ëŸ¼ì— .dtë¥¼ ë¶™ì—¬ ë‚ ì§œ ì†ì„±ì„ .ìœ¼ë¡œ êº¼ë‚´ ì“¸ ìˆ˜ ìˆë‹¤. \n",
    "all_data['transaction_month'] = all_data['transaction_date'].dt.month "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065b7c69",
   "metadata": {},
   "source": [
    "### ë°ì´í„° í•©ì¹˜ê¸° \n",
    "ğŸ”¹ merge â†’ â€œê¸°ì¤€ ì—´ë¡œ ì¡°ì¸í•˜ëŠ” ê°€ë¡œ ê²°í•© (JOIN)â€  \n",
    "ğŸ”¹ concat â†’ â€œê°™ì€ êµ¬ì¡° ë°ì´í„°ë¥¼ ë‹¨ìˆœíˆ ì´ì–´ë¶™ì´ëŠ” ì„¸ë¡œ ê²°í•© (UNION ALLê³¼ ìœ ì‚¬)â€  \n",
    "ğŸ”¹ union â†’ â€œconcatê³¼ ë¹„ìŠ·í•˜ì§€ë§Œ ì¤‘ë³µì„ ì œê±°í•˜ëŠ” ì„¸ë¡œ ê²°í•© (SQL UNIONê³¼ ë™ì¼)â€\n",
    "| ê¸°ëŠ¥         | ê³µí†µì            | ì°¨ì´ì                               |\n",
    "| ---------- | ------------- | -------------------------------- |\n",
    "| **merge**  | DataFrame í•©ì¹˜ê¸° | ê³µí†µ ì»¬ëŸ¼(key) ê¸°ì¤€ìœ¼ë¡œ **ê°€ë¡œ ê²°í•© (JOIN)** |\n",
    "| **concat** | DataFrame í•©ì¹˜ê¸° | ë‹¨ìˆœíˆ **ì„¸ë¡œë¡œ ìŒ“ê¸°** (ì¤‘ë³µ ìœ ì§€)           |\n",
    "| **union**  | DataFrame í•©ì¹˜ê¸° | **ì„¸ë¡œë¡œ ìŒ“ê³  ì¤‘ë³µ ì œê±°** (SQL UNIONê³¼ ë™ì¼) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae797dd",
   "metadata": {},
   "source": [
    "## Stage4. ë°ì´í„° ì „ì²˜ë¦¬(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136aa5d2",
   "metadata": {},
   "source": [
    "### ë„ì…\n",
    "ì´ë²ˆ ìŠ¤í…Œì´ì§€ì—ì„œëŠ” ì•„íŒŒíŠ¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì •ë¦¬í•˜ëŠ” ì‘ì—…ì„ ì§„í–‰í•  ê²ƒì…ë‹ˆë‹¤.  \n",
    "ê°€ì§€ê³  ìˆëŠ” ë°ì´í„°ì—ëŠ” ì•„íŒŒíŠ¸ì˜ ì „ìš©ë©´ì , ì•„íŒŒíŠ¸ ì´ë¦„, ê·¸ë¦¬ê³  ì¸µìˆ˜ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.   \n",
    "ì´ë¥¼ ì´ìš©í•´ ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ” ì í•©í•œ í˜•íƒœì˜ ë°ì´í„°ë¡œ ë³€í™˜í•  ì˜ˆì •ì…ë‹ˆë‹¤. \n",
    "\n",
    "### ëª©í‘œ\n",
    "- ì•„íŒŒíŠ¸ ì´ë¦„ì„ ì´ìš©í•´ ê°€ê²©ì´ ë¹„ìŠ·í•œ ë‹¨ì§€ ë¼ë¦¬ ë¬¶ê¸°\n",
    "- ì•„íŒŒíŠ¸ ì„¸ê¸ˆ í˜œíƒì„ ê¸°ì¤€ìœ¼ë¡œ ì „ìš©ë©´ì  ë°ì´í„° ì „ì²˜ë¦¬\n",
    "- ì¸µìˆ˜ì— ë”°ë¼ ì¸ê¸°ê°€ ì ì€ ë§¤ë¬¼ì„ ë°˜ì˜í•´ ì „ì²˜ë¦¬ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4dc872",
   "metadata": {},
   "source": [
    "### 1. ë°ì´í„° ë¶„ì„ ì „ ì¤€ë¹„\n",
    "[ë¬¸ì œ1] ë¹ˆì¹¸ì„ ì±„ì›Œ ë°ì´í„°í”„ë ˆì„ì˜ ì¸ë±ìŠ¤ë¥¼ ì´ˆê¸°í™”í•´ ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811fe863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd. options.mode.chained_assignment = None # ì—°ì‡„í• ë‹¹ ê²½ê³  ìˆ¨ê¸°ëŠ” ì½”ë“œ # ë°ì´í„° í•©ì¹ ë•Œ ê²½ê³  ë°œìƒ ë„ìš°ì§€ ë§ê³  ì¡°ìš©íˆ ì‹¤í–‰í•´. ('Warn'-ê²½ê³ í‘œì‹œ, 'None'-ê²½ê³ ë„ê¸°, 'Raise'-ê²½ê³  ëŒ€ì‹  ì—ëŸ¬ë¡œ ì¤‘ë‹¨)\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "train['train_test'] = 'train'\n",
    "test['train_test'] = 'test'\n",
    "all_data = pd.concat([train, test])\n",
    "all_data = all_data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ê²½ê³  ìˆ¨ê¸°ëŠ” options.mode.chained_assignment = None ëŒ€ì‹  \n",
    "# loc[] ì‚¬ìš©í•´ì„œ ì¢€ ë” ëª…í™•íˆ í‘œí˜„í•˜ëŠ” ë²•. \n",
    "# pandasê°€ ë³µì‚¬ë³¸ì„ ìˆ˜ì •í•˜ëŠ” ê±´ì§€ í˜¼ë™í•˜ì§€ ì•Šë„ë¡. ì›ë³¸ ìˆ˜ì •ì´ë¼ê³  ëª…ì‹œ.\n",
    "\n",
    "# .locì„ ì‚¬ìš©í•˜ì—¬ ëª…í™•íˆ ì›ë³¸ì˜ íŠ¹ì • ì—´ì„ ìˆ˜ì •\n",
    "# train.loc[:, 'train_test'] = 'train'\n",
    "# test.loc[:, 'train_test'] = 'test'\n",
    "\n",
    "# ë‘ ë°ì´í„°í”„ë ˆì„ ê²°í•© (í–‰ ë°©í–¥)\n",
    "# all_data = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "all_data.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b150b3",
   "metadata": {},
   "source": [
    "### 2. ì•„íŒŒíŠ¸ ì´ë¦„ ì „ì²˜ë¦¬(1)\n",
    "[ë¬¸ì œ2] ë¹ˆì¹¸ì„ ì±„ì›Œ kmeans ë³€ìˆ˜ì— K-means í´ëŸ¬ìŠ¤í„°ë§ ëª¨ë¸ì„ ì„ ì–¸í•´ ë´…ì‹œë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4500a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np \n",
    "\n",
    "# í‰ê· ê°’ì„ êµ¬í•  ë•Œì—ëŠ” train ë°ì´í„°ì—ì„œ êµ¬í•œë‹¤.\n",
    "train = all_data[all_data['train_test'] == 'train']\n",
    "\n",
    "# ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë¡œ ë³€í™˜\n",
    "train['transaction_real_price'] = train['transaction_real_price'].str.replace(',','').astype('int')\n",
    "\n",
    "# ì•„íŒŒíŠ¸ ì´ë¦„ì„ ê¸°ì¤€ìœ¼ë¡œ í‰ê·  ì‹¤ê±°ë˜ê°€ êµ¬í•˜ê¸°\n",
    "data = train[['apt_name', 'transaction_real_price']] \n",
    "data = data.groupby('apt_name').mean()\n",
    "arr = data['transaction_real_price'].to_numpy().reshape(-1,1) \n",
    "# to_numpy í†µí•´ ìˆœìˆ˜í•œ ìˆ«ì ë°°ì—´ë¡œ ë³€í™˜. ê³„ì‚° ìš©ì´í•˜ë„ë¡. # reshape(-1,1)ì€ 1ì°¨ì› -> 2ì°¨ì› ë°°ì—´ (n,1)í˜•íƒœë¡œ ë§Œë“¤ì–´ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜.\n",
    "# (n,) : 1ì°¨ì› -> ëª¨ë¸ì´ ì¸ì‹ ëª»í•¨. [35000, 42000, 39000]\n",
    "# (n, 1) : 2ì°¨ì› -> ì¸ì‹ ê°€ëŠ¥. [[35000], [42000], [39000]]\n",
    "# (-1,1) ì˜ë¯¸ëŠ” -1: í–‰ ê°œìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚°, 1: ì—´ì´ 1ê°œì§œë¦¬ 2ì°¨ì›” ë°°ì—´ë¡œ ë§Œë“¤ë¼ëŠ” ëœ». \n",
    "\n",
    "# ê°€ê²©ì„ ê¸°ì¤€ìœ¼ë¡œ ì•„íŒŒíŠ¸ êµ°ì§‘í™”\n",
    "k = 5\n",
    "kmeans = KMeans(n_cluster=k, n_init=10)\n",
    "kmeans.fit(arr)\n",
    "\n",
    "# ê°€ê²©ì„ ê¸°ì¤€ìœ¼ë¡œ êµ°ì§‘ì˜ ìˆœì„œë¥¼ ì •ë ¬í•˜ê¸° ìœ„í•´ ì¸ë±ìŠ¤ë¥¼ ì¶”ì¶œ\n",
    "sort_order = np.argsort(kmeans.cluster_centers_.flatten()) # np.argsort() ì •ë ¬ëœ ìˆœì„œì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜. \n",
    "# flatten()ì€ 1ì°¨ì› í•œì¤„ë¡œ í´ì£¼ëŠ” í•¨ìˆ˜. ì¸ë±ìŠ¤ ì…€ë•Œ ìœ ìš©í•˜ê¸° ë•Œë¬¸ì— ê°™ì´ ì“°ì„. \n",
    "# ë‚´ë¦¼ì°¨ìˆœì€ np.argsort()[::-1] ë˜ëŠ” np.argsort(-arr) \n",
    "\n",
    "# êµ°ì§‘í™” ê²°ê³¼ë¥¼ ê°€ê²© ìˆœì„œëŒ€ë¡œ ì¬í• ë‹¹\n",
    "labels = np.zeros_like(kmeans.labels_)\n",
    "for i, cluster in enumerate(sort_order):\n",
    "    labels[kmeans.labels_ == cluster] = i \n",
    "    \n",
    "# êµ°ì§‘í™” ê²°ê³¼ì™€ ê°€ê²©ì„ ë°ì´í„°ì— ì¶”ê°€\n",
    "data['cluste'] = labels\n",
    "data = data.reset_indec()\n",
    "data = data[['apart_name', 'cluster']]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b9abb9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e11b2dfe",
   "metadata": {},
   "source": [
    "### 3. ì•„íŒŒíŠ¸ ì´ë¦„ ì „ì²˜ë¦¬(2)\n",
    "[ë¬¸ì œ3] ë¹ˆì¹¸ì„ ì±„ì›Œ ìœ„ì—ì„œ êµ¬í•œ ì•„íŒŒíŠ¸ì˜ ë¶„ë¥˜ ê²°ê³¼ë¥¼ 'all_data'ì— 'apt_name'ì„ ê¸°ì¤€ìœ¼ë¡œ left join ì—°ì‚°ì„ í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4b9ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.merge(all_data, data, how='left', left_on='apt_name', right_on='apt_name')\n",
    "\n",
    "cluster_mode = all_data.loc[all_data['train_test'] == 'train', 'cluster'].mode()\n",
    "all_data['cluster'] = all_data['cluster'].fillna(cluster_mode)\n",
    "\n",
    "all_data['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74285b2",
   "metadata": {},
   "source": [
    "### 4. ì•„íŒŒíŠ¸ ë©´ì  ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e3d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_area_bucket(area):\n",
    "    if area < 60: #59íƒ€ì…\n",
    "        return 0\n",
    "    elif area < 85: #84íƒ€ì…\n",
    "        return 1\n",
    "    else:\n",
    "        return 2 \n",
    "    \n",
    "all_data['bucket_area']= all_data['exclusive_use_area'].apply(make_area_bucket)\n",
    "all_data['bucket_area'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef479e69",
   "metadata": {},
   "source": [
    "### 5. ì¸µìˆ˜ ì „ì²˜ë¦¬\n",
    "[ë¬¸ì œ4] ë¹ˆì¹¸ì„ ì±„ì›Œ floor í”¼ì²˜ë¥¼ í™œìš©í•´ ì „ì²˜ë¦¬í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ ë´…ì‹œë‹¤.\n",
    "\n",
    "ì•„íŒŒíŠ¸ ì¸µìˆ˜ëŠ” ì €ì¸µì¼ ê²½ìš°, ì¼ë°˜ì ìœ¼ë¡œ ê°€ê²©ì´ ë‚®ìŠµë‹ˆë‹¤.  \n",
    "ê·¸ë ‡ê¸° ë•Œë¬¸ì— 3ì¸µ ì´í•˜ì˜ ì¸µìˆ˜ëŠ” ë”°ë¡œ ë¶„ë¥˜í•´ ì „ì²˜ë¦¬ í•˜ë„ë¡ í•´ë³´ê² ìŠµë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e21154",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['low_floor'] = all_data['floor'].apply(lambda x: 0 if x <= 3 else 1)\n",
    "all_data['low_floor'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24763c0c",
   "metadata": {},
   "source": [
    "## Stage5. ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2778b053",
   "metadata": {},
   "source": [
    "### 1.ë„ì…\n",
    "ì•ì—ì„œ ì „ì²˜ë¦¬í•œ ë°ì´í„°ë“¤ì„ ì´ìš©í•´ ëª¨ë¸ì„ í•™ìŠµí•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "ì–´ë–¤ ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ì‹¤ê±°ë˜ê°€ ì˜ˆì¸¡ì— ë„ì›€ì´ ë˜ëŠ”ì§€ ê²€ì¦í•  ì°¨ë¡€ì…ë‹ˆë‹¤.\n",
    "ì¶”ê°€ì ìœ¼ë¡œ ë°ì´í„°ê°€ ì‹œê°„ ìˆœì„œëŒ€ë¡œ êµ¬ì„±ë˜ì–´ ìˆê¸° ë•Œë¬¸ì—, ê·¸ì— ë§ê²Œ í•™ìŠµ ë°ì´í„°ì™€ ê²€ì¦ ë°ì´í„°ë¥¼ ë‚˜ëˆ  ê²€ì¦ì„ ì§„í–‰í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "### 2. ëª©í‘œ\n",
    "- ëª¨ë¸ í•™ìŠµ ë° ì ì •í•œ í”¼ì²˜ ì„ íƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e905a9",
   "metadata": {},
   "source": [
    "### 1. ë°ì´í„° ë¶„ì„ ì „ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a59114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sampled_submission.csv')\n",
    "interest_rate = pd.read_Csv('interest_rate.csv')\n",
    "\n",
    "train['train_test'] = 'train'\n",
    "test['train_test'] = 'test'\n",
    "all_data = pd.concat([train, test])\n",
    "all_data = all_data.reset_index(drop=True)\n",
    "\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a510fc",
   "metadata": {},
   "source": [
    "### 2. ê°€ê²© ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd350d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_int(string):\n",
    "    if type(string) == str:\n",
    "        string = string.replace(',','')\n",
    "        return int(string)\n",
    "    else:\n",
    "        return string\n",
    "    \n",
    "all_data['trransaction_real_price'] = all_data['transaction_real_price'].apply(str_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bb7402",
   "metadata": {},
   "source": [
    "### 3. ì•„íŒŒíŠ¸ í‚¤ê°’ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b12ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['apartment_id'] = all_data.roupby(['sigungu', 'apt_name']).ngroup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaeb57a",
   "metadata": {},
   "source": [
    "### 4. ë‚ ì§œ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "[ë¬¸ì œ1] ë¹ˆì¹¸ì„ ì±„ì›Œ all_dataë¥¼ transaction_Dateë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì„¸ìš”,   \n",
    "ê·¸ë¦¬ê³  ì¸ë±ìŠ¤(index)ë¥¼ ë¦¬ì…‹(reset)í•´ ì£¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cc497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tran_date(x):\n",
    "    if type(x) === int:\n",
    "        if x < 10:\n",
    "            return '0'+str(x)\n",
    "        else:\n",
    "            return str(x)\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "# ê°„ë‹¨ í•œì¤„ í•¨ìˆ˜ : return f\"{int(x):02d}\n",
    "\n",
    "all_data['transaction_day'] = all_data['transaction_day'].apply(preprocess_tran_date)\n",
    "all_data['transaction_date'] = all_data['transaction_year_month'].astype(int).astype(str)+all_data['transaction_day'].astype(str)\n",
    "all_data['transaction_date'] = pd.to_datetime(all_data['transaction_date'])\n",
    "all_data = all_data.sort_values('transaction_date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbc109a",
   "metadata": {},
   "source": [
    "| í‚¤ì›Œë“œ               | ì–´ë–¤ ë°ì´í„°    | ê²°ê³¼         | ê¸°ì–µí•˜ê¸°      |\n",
    "| ----------------- | --------- | ---------- | --------- |\n",
    "| **sort_values()** | DataFrame | ì •ë ¬ëœ ë°ì´í„° ë°˜í™˜ | SQL ORDER BY ê°œë…|\n",
    "| **np.sort()**     | NumPy ë°°ì—´  | ì •ë ¬ëœ ê°’      | â€œê°’ ì •ë ¬â€    |\n",
    "| **np.argsort()**  | NumPy ë°°ì—´  | ì •ë ¬ ìˆœì„œ ì¸ë±ìŠ¤  | â€œì¸ë±ìŠ¤ê°’ ë°˜í™˜â€   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a52453",
   "metadata": {},
   "source": [
    "### 5. ìµœê·¼ì— ê±°ë˜ëœ ê°€ê²© êµ¬í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49cefb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "def make_area_bucket(area):\n",
    "    if area < 60: # 59íƒ€ì…\n",
    "        return 0\n",
    "    elif area < 85: # 84íƒ€ì…\n",
    "        return 1\n",
    "    else:\n",
    "        return 2 \n",
    "    \n",
    "# ì•„íŒŒíŠ¸ ë©´ì  ì „ì²˜ë¦¬\n",
    "all_data['bucket_area'] = all_data['exclusive_use_area'].apply(make_area_bucket)\n",
    "\n",
    "def get_recent_price(idx, all_data):\n",
    "    temp_df = all_data.loc[:idx]\n",
    "    temp_df = temp_df[temp_df\n",
    "        (temp_df['transaction_date'] < row['transaction_date']) &\n",
    "        (temp_df['bucket_area'] == row['bucket_area'])\n",
    "    ]\n",
    "    if len(temp_df) == 0:\n",
    "        temp_df = all_data[ \n",
    "            (all_data['transaction_date'] < datetime.strptime('2016-01-01', '%Y-%m-%d')) &\n",
    "            (all_data['bucket_area'] == row['bucket_area']\n",
    "        )]\n",
    "    \n",
    "    # ì•„íŒŒíŠ¸ ì•„ì´ë”” ê°™ì€ ê²ƒ ì°¾ê¸°\n",
    "    recent_price = temp_df[(temp_df['apartment_id'] == row['apartment_id'])]\n",
    "    if len(recent_price) == 0:\n",
    "        recent_price = temp_df[(temp_df['sigungu'] == row['sigungu'])]\n",
    "        recent_price = recent_price.iloc[-1]['transaction_real_price']\n",
    "    else:\n",
    "        recent_price = recent_price.iloc[-1]['transaction_real_price']\n",
    "        \n",
    "    if recent_price is None:\n",
    "        recent_price = temp_df['transaction_real_price'].mean() # 2019ë…„ ì „ì²´í‰ê· \n",
    "        \n",
    "    return recent_price\n",
    "for idx, row in tqdm(all_data.iterrows(), total = all_data.shape[0]):\n",
    "    if row['train_test'] == 'test' :\n",
    "        continue \n",
    "    all_data.loc[idx, 'recent_price'] = get_recent_price(idx, all_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaaabb9",
   "metadata": {},
   "source": [
    "### 6. ì•„íŒŒíŠ¸ì˜ ìµœê·¼ ê±°ë˜ëŸ‰ êµ¬í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574fbc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "for idx, row in tqdm(all_data.iterrows(), total = all_data.shape[0]):\n",
    "    # transaction_dateê°€ 2014-03-30 ë‚ ì§œ ì´ì „ ë°ì´í„°ì¸ ê²½ìš°, 2014-03-30 ~ 2014-01-01 ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. \n",
    "    if row['trandaction_date'] <= datetime.strptime('2014-03-30', \"%Y-%m-%d\"): \n",
    "        start_day = datetime.strptime('20214-03-30', \"%Y-%m-%d\")\n",
    "        end_day = datetime..strptime('2014-01-01', \"%Y-%m-%d\")\n",
    "        cnt = len(all_data[(all_data['transaction_date'] >= start_day) & (all_data['transaction_date'] < end_day) & (all_data['sigungu'] == row['sigungu'])]) \n",
    "        \n",
    "    # ê±°ë˜ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ 3ê°œì›” ì´ì „ ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ ë´…ì‹œë‹¤.\n",
    "    else:\n",
    "        start_day = row['transaction_date'] - timedelta(days=90)\n",
    "        end_day = row['transaction_date']\n",
    "        cnt = len(all_data[(all_data['transaction_date'] >= start_day) & (all_data['transaction_date'] < end_day) & (all_data['sigungu'] == row['sigungu'])])\n",
    "    \n",
    "    all_data.loc[idx, 'transaction_cnt'] = cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bc9f6a",
   "metadata": {},
   "source": [
    "### 7. ê¸ˆë¦¬ ë°ì´í„° ì¶”ê°€í•˜ê¸° \n",
    "[ë¬¸ì œ2]\n",
    "ë¬¸ìì—´ í˜•ì‹ì˜ ë‚ ì§œ ë°ì´í„°ë¥¼, datetime í˜•íƒœë¡œ ë³€ê²½í•´ ë´…ì‹œë‹¤.  \n",
    "ë¨¼ì € ë‚ ì§œ ë°ì´í„°ë¥¼ '2023-12-01' í˜•íƒœë¡œ ë³€ê²½í•´ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9d0a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interest_rateì— ë“¤ì–´ìˆëŠ” ë‚ ì§œ ë°ì´í„°ëŠ” ê¸ˆë¦¬ê°€ ë³€ë™ëœ ë‚ ì§œ. \n",
    "# ê·¸ë ‡ê¸° ë•Œë¬¸ì— ê±°ë˜ì¼ì ê¸°ì¤€ ìµœê·¼ ê¸ˆë¦¬ê°€ ë³€ë™ëœ ë‚ ì§œì˜ ê¸ˆë¦¬ë¥¼ ì‚¬ìš©í•˜ë©´ ë„ë¯¸.\n",
    "\n",
    "# ê¸ˆë¦¬ ë³€ë™ì¼ì ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•´ ë´…ì‹œë‹¤. pd.to_datetime()í•¨ìˆ˜ì—ëŠ” '2023-01-01'í˜•íƒœì˜ ë¬¸ìì—´ë¡œ ë„£ì–´ì•¼ í•¨.\n",
    "# 'ì›”ì¼'ì„ '01ì›”01ì¼' -> '01-01'ë¡œ ë³€ê²½ \n",
    "\n",
    "def make_date(row):\n",
    "    '''\n",
    "    \"ì—°ë„'ì™€ 'ì›”ì¼' ì»¬ëŸ¼ì„ ì¡°í•©í•´ YYYY-MM-DD ë¬¸ìì—´ë¡œ ë³€í™˜í•´ì•¼ í•¨\n",
    "    (ex. '2023', '1ì›”13ì¼' -> '2023-01-13')\n",
    "    '''\n",
    "    year = str(row['ì—°ë„'])\n",
    "    \n",
    "    # 'ì›”', 'ì¼' ì œê±°, ê³µë°± ì œê±°\n",
    "    monthday = str(row['ì›”ì¼']).replace('ì›”','').replace('dlf','').strip()\n",
    "    \n",
    "    # ê³µë°± ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬ -> ['1', '13'] í˜•íƒœ\n",
    "    parts = monthday.split()\n",
    "    if len(parts) == 2:\n",
    "        month = parts[0].zfill(2) # zfill(n) ì™¼ìª½ì— 0 ì¶”ê°€í•´ì„œ ë¬¸ìì—´ ì „ì²´ ê¸¸ì´ë¥¼ nìœ¼ë¡œ ë§ì¶¤. zero fill 0ìœ¼ë¡œ ì±„ìš´ë‹¤ëŠ” ì˜ë¯¸.\n",
    "        day = parts[1].zfill(2)\n",
    "    else:\n",
    "        # í˜¹ì‹œ ë°ì´í„°ê°€ '0113' í˜•íƒœì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ëŒ€ë¹„\n",
    "        month = monthday[:2].zfill(2)\n",
    "        day = monthday[2:].zfill(2) \n",
    "    return f\"{year}-{month}-{day}\" \n",
    "    \n",
    "interest_rate['ë‚ ì§œ'] = interest_rate.apply(lambda x: make_date(x), axis=1) # axis=0 ì„¸ë¡œ ë°©í–¥ ê° ì—´(colums)ì— í•¨ìˆ˜ ì ìš©, axis=1 ê°€ë¡œ ë°©í–¥ ê° í–‰(row)ì— í•¨ìˆ˜ ì ìš©\n",
    "interest_rate['ë‚ ì§œ'] = pd.to_datetime(interest_rate['ë‚ ì§œ']\n",
    "interest_rate['ë‚ ì§œ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffbec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‚ ì§œì— ë§ê²Œ ê¸ˆë¦¬ë¥¼ ì ìš©í•´ ì¤ì‹œë‹¤.\n",
    "for idx, row in tqdm(all.iterrows(), total = all_data.shape[0]):\n",
    "    date = row['transaction_date']\n",
    "    rate = interest_rate[interest_rate['ë‚ ì§œ'] <= date].iloc[0]['ê¸ˆë¦¬']\n",
    "    all_data.loc[idx, 'interest_rate'] = rate \n",
    "\n",
    "# ì—°ì›” ë°ì´í„° ì¶”ê°€\n",
    "all_data['transaction_year'] = all_data['transaction_date'].dt.year\n",
    "all_data['transaction_month'] = all_data['transaction_date'].dt.month "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3291d20f",
   "metadata": {},
   "source": [
    "### 8. ì•„íŒŒíŠ¸ ì´ë¦„ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "[ë¬¸ì œ2] ì•„íŒŒíŠ¸ ì´ë¦„(apt_name)ë³„ ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€(transaction_real_price)ì˜ í‰ê· ì„ êµ¬í•´ë´…ì‹œë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3dbf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "import numpy as np \n",
    "\n",
    "# ì•„íŒŒíŠ¸ ë³„ë¡œ ê°€ê²© í‰ê· ê°’ êµ¬í•˜ê¸°\n",
    "train = all_data[all_data['tran_test'] == 'train']\n",
    "data = train[['apt_name', 'transaction_real_price']]\n",
    "\n",
    "data = data.groupby('apt_name').mean()\n",
    "arr = data['transaction_rea;_price'].to_numpy().reshape(-1,1)\n",
    "\n",
    "# ê°€ê²©ì„ ê¸°ì¤€ìœ¼ë¡œ ì•„íŒŒíŠ¸ êµ°ì§‘í™”\n",
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k, n_init=10)\n",
    "kmeans.fit(arr)\n",
    "\n",
    "# ê°€ê²©ì„ ê¸°ì¤€ìœ¼ë¡œ êµ°ì§‘ì˜ ìˆœì„œë¥¼ ì •ë ¬í•˜ê¸° ìœ„í•´ ì¸ë±ìŠ¤ë¥¼ ì¶”ì¶œ\n",
    "sort_order = np.argsort(kmeans.cluster_centers_.flatten())\n",
    "\n",
    "# êµ°ì§‘í™” ê²°ê³¼ë¥¼ ê°€ê²© ìˆœì„œëŒ€ë¡œ ì¬í• ë‹¹\n",
    "labels = np.zeros_like(kmeans.labels_)\n",
    "for i, cluster in enumerate(sort_order):\n",
    "    labels[kemeans.labels_==cluster] = i\n",
    "    \n",
    "# êµ°ì§‘í™” ê²°ê³¼ì™€ ê°€ê²©ì„ ë°ì´í„°ì— ì¶”ê°€\n",
    "data['cluster'] = labels\n",
    "data = data.reset_index()\n",
    "data = data[['apt_name', 'cluster']]\n",
    "\n",
    "all_data = pd.merge(all_data, data, how='left', left_on='apt_name', right_on='apt_name')\n",
    "\n",
    "cluster_mode = all_data.loc[all_data['train_test'] == 'train', 'cluste'].mean()[0]\n",
    "all_data['cluster'] = all_data['cluster'].fillna(cluster_mode)\n",
    "\n",
    "all_data['cluster'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dbc354",
   "metadata": {},
   "source": [
    "### 9. ì¸µìˆ˜ ì „ì²˜ë¦¬\n",
    "[ë¬¸ì œ3] lambda í•¨ìˆ˜ë¥¼ ì´ìš©í•´ 'floor'í”¼ì²˜ê°€ 3ì¸µ ì´í•˜ì¸ ê²½ìš° 0,  \n",
    "ì´ì™¸ì˜ ê²½ìš°ëŠ” 1ì¸ ìƒˆë¡œìš´ í”¼ì²˜ë¥¼ ë§Œë“¤ì–´ ë´…ì‹œë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14959b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['low_floor'] = all_data['floor'].apply(lambda x: 0 if x <= 3 else 1)\n",
    "all_date['low_floor'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87514612",
   "metadata": {},
   "source": [
    "### 10. ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦\n",
    "[ë¬¸ì œ4] ë¹ˆì¹¸ì„ ì±„ì›Œ ì˜µíˆ¬ë‚˜ë¥¼ ì´ìš©í•´ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ìµœì í™”í•´ ë´…ì‹œë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7203f3",
   "metadata": {},
   "source": [
    "ì´ë²ˆ ë¬¸ì œì—ì„œëŠ” ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì„ ì´ìš©í•´ ëª¨ë¸ì„ ë§Œë“¤ê² ìŠµë‹ˆë‹¤.  \n",
    "ê·¸ë¦¬ê³  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ìµœì í™” í•˜ê¸° ìœ„í•´ ì˜µíˆ¬ë‚˜(Optuna) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ ë´…ì‹œë‹¤.  \n",
    "ë² ì´ì¦ˆ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ ê¸°ë°˜ìœ¼ë¡œ íƒìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.  \n",
    "ì´ˆê¸°ì—ëŠ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì˜ ëœë¤í•œ ì¡°í•©ì„ ì„ íƒí•˜ê³ , ëª©ì  í•¨ìˆ˜ë¥¼ ì´ìš©í•´ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤.  \n",
    "ì´í›„ í‰ê°€ëœ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ë‚˜ì€ ì„±ëŠ¥ì´ ê¸°ëŒ€ë˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ì˜ì—­ìœ¼ë¡œ ì ì§„ì ìœ¼ë¡œ íƒìƒ‰í•˜ë©°, ë” ë‚˜ì€ ì¡°í•©ì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤.   \n",
    "ì´ ê³¼ì •ì„ ë°˜ë³µí•˜ì—¬ ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©ì„ ì°¾ìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc25887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandaomForesttRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna \n",
    "\n",
    "validation_year = 2022\n",
    "\n",
    "columns = [\n",
    "    'year_of_completion', 'recent_price', 'transaction_cnt', 'interest_rate', 'transaction_year',\n",
    "    'transaction_month', 'cluster', 'bucket_area', 'low_floor', \n",
    "]\n",
    "\n",
    "train_x = all_data.loc[(all_data['train_test'] == 'train') & (all_data['transaction_year'] < validation_year), columns] \n",
    "train_y = all_data.loc[(all_data['train_test'] == 'train') & (all_data['transaction_year'], 'transaction_real_price']\n",
    "                       \n",
    "val_x = all.data.loc[(all_data['train_test'] == 'train') & (all_data['transaction_year'] == validation_year), columns]\n",
    "val_y = a;;_data.loc[(all_data['train_test'] == 'train') & (all_data['transaction_year'] == validation_year), 'transaction_real_price'] \n",
    "\n",
    "def objective(trial) : \n",
    "    # í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ëŒ€ìƒ\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 100)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
    "    \n",
    "    # RandomForestRegressor ëª¨ë¸ í•™ìŠµ\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    model.fit(train_x, train_y)\n",
    "    \n",
    "    # ê²€ì¦ ë°ì´í„°ë¡œ í‰ê°€\n",
    "    y_pred = model.predict(val_x)\n",
    "    mse = mean_squared_error(val_y, y_pred)\n",
    "    return mse \n",
    "\n",
    "# Optunaë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰\n",
    "study = optuna.create_study(direction='minimize') # ëª©í‘œëŠ” ìµœì†Œí™” \n",
    "    # direction='minimize' â†’ ì†ì‹¤ í•¨ìˆ˜(loss, RMSE ë“±) ìµœì†Œí™” \n",
    "    # direction='maximize' â†’ ì •í™•ë„(accuracy, F1 ë“±) ìµœëŒ€í™”\n",
    "study.optimize(objective, n_traials=50) # 50íšŒ ë°˜ë³µí•˜ì—¬ íƒìƒ‰\n",
    "\n",
    "# ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ ì¶œë ¥\n",
    "best_params = study.best_params\n",
    "print(\"Best Params:\", best_params)\n",
    "\n",
    "\n",
    "# ì‹¤í–‰í•˜ë©´ ë‚ ì§œ ì‹œë¶„ì´ˆ, Trial 1 ë¶€í„° 50ê¹Œì§€ ì§„í–‰ê³¼ì • ë¦¬ìŠ¤íŠ¸ ëœ¨ê³  \n",
    "# \"Best Params: {'n_estimator':100, 'max_depth':5}\" ì¶œë ¥ë¨. ë² ìŠ¤íŠ¸ íŒŒë¼ë¯¸í„° ê°’ í™•ì¸."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0cb8f3",
   "metadata": {},
   "source": [
    "ğŸ”¹ n_estimators â€” íŠ¸ë¦¬(tree)ì˜ ê°œìˆ˜\n",
    "\n",
    "ëª¨ë¸ì´ ëª‡ ê°œì˜ ê²°ì •íŠ¸ë¦¬(Decision Tree)ë¥¼ ë§Œë“¤ì–´ì„œ ì˜ˆì¸¡í• ì§€ë¥¼ ê²°ì •.  \n",
    "ë„ˆë¬´ ì ìœ¼ë©´ í•™ìŠµ ë¶€ì¡±(underfitting), ë„ˆë¬´ ë§ìœ¼ë©´ ê³¼ì í•©(overfitting) ìœ„í—˜  \n",
    "  \n",
    "ğŸ”¹*max_depth (ë˜ëŠ” depth) â€” ê° íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´\n",
    "\n",
    "í•œ íŠ¸ë¦¬ê°€ ì–¼ë§ˆë‚˜ â€œê¹Šê²Œâ€ ë¶„ê¸°í• ì§€ë¥¼ ê²°ì •.  \n",
    "íŠ¸ë¦¬ì˜ â€œì§ˆë¬¸ ë‹¨ê³„â€ê°€ ëª‡ ë²ˆê¹Œì§€ ê°€ëŠ¥í•œì§€ë¥¼ ì •í•˜ëŠ” ê²ƒ  \n",
    "(ì˜ˆ: â€œê°€ê²©ì´ 1ì–µ ì´ìƒì¸ê°€?â€ â†’ â€œì„œìš¸ì¸ê°€?â€ â†’ â€œ84ã¡ ì´ìƒì¸ê°€?â€ â€¦)\n",
    "\n",
    "âœ… ì •ë¦¬ ìš”ì•½\n",
    "| íŒŒë¼ë¯¸í„°           | ì˜ë¯¸                 | ì¡°ì ˆ íš¨ê³¼                |\n",
    "| -------------- | ------------------ | -------------------- |\n",
    "| `n_estimators` | ëª¨ë¸ì´ í•™ìŠµí•  **íŠ¸ë¦¬ì˜ ê°œìˆ˜** | ë§ì„ìˆ˜ë¡ ì„±ëŠ¥â†‘, ê³¼ì í•©/ì†ë„â†“ ì£¼ì˜ |\n",
    "| `max_depth`    | ê° íŠ¸ë¦¬ì˜ **ê¹Šì´(ë³µì¡ë„)**  | ê¹Šì„ìˆ˜ë¡ ë³µì¡, ê³¼ì í•© ìœ„í—˜      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9bd92d",
   "metadata": {},
   "source": [
    "### 11. ëª¨ë¸ í•™ìŠµ\n",
    "[ë¬¸ì œ5] ë¹ˆì¹¸ì„ ì±„ì›Œ ì˜ˆì¸¡í•œ ê²°ê³¼ë¥¼ MAEë¡œ í‰ê°€í•´ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error \n",
    "\n",
    "# ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ ì¬í•™ìŠµ\n",
    "best_model = RandomForestRegressor(n_estimators=best_params['n_estimators'], \n",
    "                                   max_depth=best_params['max_depth'])\n",
    "best_model.fit(train_x, train_y)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "pred_val_ls = best_model.predict(val_x)\n",
    "\n",
    "mae = maean_absolute_error(val_y, pred_val_ls)\n",
    "print(mae) \n",
    "\n",
    "# mean_absolute_error()\n",
    "# â†’ ì‹¤ì œê°’(val_y)ê³¼ ì˜ˆì¸¡ê°’(pred_val_ls)ì˜ ì°¨ì´(ì˜¤ì°¨)ì˜ ì ˆëŒ“ê°’ í‰ê· ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002b0c39",
   "metadata": {},
   "source": [
    "| í•­ëª©           | í˜„ì¬ ìƒí™©                        | í•´ì„                |\n",
    "| ------------ | ---------------------------- | ----------------- |\n",
    "| MAE = 26,349 | ë‹¨ìœ„ê°€ **ë§Œì›**ì´ë¼ë©´ â†’ ì•½ 2.6ì–µ ì˜¤ì°¨    | âŒ ë§¤ìš° í¼ (ëª¨ë¸ ê°œì„  í•„ìš”) |\n",
    "|              | ë‹¨ìœ„ê°€ **ì›**ì´ë¼ë©´ â†’ ì•½ 26,000ì› ì˜¤ì°¨  | âœ… ë§¤ìš° ì–‘í˜¸           |\n",
    "|              | ë°ì´í„°ê°€ ìŠ¤ì¼€ì¼ë§(normalized) ë˜ì–´ ìˆë‹¤ë©´ | âš ï¸ ë³µì› í›„ ì¬í‰ê°€ í•„ìš”    |\n",
    "\n",
    "MAE = 26349ê°€ í°ì§€ ì‘ì€ì§€ëŠ” íƒ€ê¹ƒì˜ ë‹¨ìœ„ì™€ ë²”ìœ„ì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤.  \n",
    "ë§Œì•½ ì‹¤ê±°ë˜ê°€(ë§Œì› ë‹¨ìœ„)ë¥¼ ì˜ˆì¸¡ ì¤‘ì´ë¼ë©´ ì˜¤ì°¨ 2~3ì–µ ìˆ˜ì¤€ìœ¼ë¡œ ë†’ì€ í¸ì´ë¯€ë¡œ  \n",
    "ëª¨ë¸ ì„±ëŠ¥ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤ (íŠ¹ì§• ì¶”ê°€, ìŠ¤ì¼€ì¼ë§, í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • ë“±).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4a6528",
   "metadata": {},
   "source": [
    "## 12. í”¼ì²˜ ì¤‘ìš”ë„ í™•ì¸\n",
    "[ë¬¸ì œ6] ìœ„ì—ì„œ í•™ìŠµí•œ ëœë¤í¬ë ˆìŠ¤íŠ¸(Random Forest) ëª¨ë¸ì—ì„œ, í”¼ì²˜ ì¤‘ìš”ë„ë¥¼ ì¶”ì¶œí•´ ë´…ì‹œë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4a5363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "importances = best_model.feature_importances_\n",
    "feature_names = train_x.colounms\n",
    "\n",
    "# í”¼ì²˜ ì¤‘ìš”ë„ì— ë”°ë¼ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì¸ë±ìŠ¤ë¥¼ ì •ë ¬\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# í”¼ì²˜ ì´ë¦„ì„ ì¤‘ìš”ë„ ìˆœì„œì— ë§ê²Œ ì¬ë°°ì—´ \n",
    "sorted_feature_names = [feature_names[i] for i in indices]\n",
    "\n",
    "# í”¼ì²˜ ì¤‘ìš”ë„ ì‹œê°í™” \n",
    "plt.figure()\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.barh(range(train_x.shape[1]), importances[indices], align=\"center\") \n",
    "plt.yticks(range(train_x.shape[1], sorted_feature_name)\n",
    "plt.ylabel(\"Features\") \n",
    "plt.xlabel(\"Importance\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663c2236",
   "metadata": {},
   "source": [
    "### 13. ì¤‘ìš” í”¼ì²˜(Feature) ì„ íƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd06718",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['bucket_area', 'low_floor', 'year_of_completion']\n",
    "\n",
    "train_filtered_x = train_x.drop(columns=drop_columns)\n",
    "val_filtered_x = val_x.drop(columns=drop_columns)\n",
    "\n",
    "best_model = RandomForestRegressor(n_estimators=best_params['n_estimators'],\n",
    "                                   max_depth=best_params['max_depth'])\n",
    "best_model.fit(train_filtered_x, train_y) \n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "pred_vsl_ls = best_model.predict(val_fitered_x)\n",
    "mae = mean_absolute_error(pred_val_ls, val_y)\n",
    "print(mae)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93df4c60",
   "metadata": {},
   "source": [
    "### 14. ì‹œê³„ì—´ ëª¨ë¸ êµì°¨ê²€ì¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f425ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for validation_year in [2018,2019,2020,2021,2022]:\n",
    "    columns = [\n",
    "        'recent_price', 'transaction_cnt', 'interest_rate', 'transaction_year', 'transaction_month', 'cluster',\n",
    "    ]\n",
    "    train_x = all_data.loc[(all_data['train_test'] == 'train') & (all_data['transaction_year'] < validation_year), columns]\n",
    "    train_y = all_data.loc[(all_data['train_test'] == 'train') & (all_data['transaction_year'] < validation_year), 'transaction_real_price']\n",
    "    \n",
    "    val_x = all_data.loc[(all_data['train_test'] == 'train') & (all_data['transaction_year'] == validation_year), columns]\n",
    "    val_y = all_data.loc[(all_data['train_test'] == 'train') & (all_data['transaction_year'] == validation_year), 'transaction_real_price']\n",
    "    \n",
    "# ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ ìƒì„± ë° í›ˆë ¨\n",
    "model_trial = RandomForestRegressor(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth']\n",
    ")\n",
    "model_trial.fit(train_x, train_y)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "pred_val_ls = model_trial.predict(val_x)\n",
    "mae = mean_absolute_error(pred_val_ls, val_y)\n",
    "print(validation_year, 'ë…„ë„ MAE:', mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f5b513",
   "metadata": {},
   "source": [
    "### 15. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f933a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "columns = [\n",
    "    'recent_price', 'transaction_cnt', 'interest_rate', 'transaction_year', 'transaction_month', 'cluster'\n",
    "]\n",
    "train_x = all_data.loc[all_datap['train_test'] == 'train', columns]\n",
    "train_y = all_data.loc[all_data['train_test'] == 'train', 'transaction_real_price']\n",
    "test_x = all_data.loc[all_data['train_test'] == 'test', columns]\n",
    "\n",
    "# ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ ìƒì„± ë° í›ˆë ¨\n",
    "model = RandomForestRegressor()\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "pred_ls = list()\n",
    "now_df = all_data.loc[all_data['train_test'] == 'train']\n",
    "test = all_data.loc[all_data['train_test'] == 'test']\n",
    "\n",
    "for idx, row in tqdm(test.iterrows(), total = test.shape[0]):\n",
    "    now_df = pd.cincat([now_df, test.loc[[idc]]])\n",
    "    test_x.loc[idx, 'recent_price'] = get_recent_price(idx, now_df)\n",
    "    \n",
    "    pred = model.predict(test_x.loc[idx:idx]) \n",
    "    \n",
    "    now_df.loc[idx, 'transaction_real_price'] = pred\n",
    "    pred_ls.append(pred[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6b0351",
   "metadata": {},
   "source": [
    "### 16. ì •ë‹µ ì œì¶œ íŒŒì¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f8b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['transaction_real_price'] = pred_ls\n",
    "submission.to_csv('submission.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23c1806",
   "metadata": {},
   "source": [
    "## Stage6. ëª¨ë¸ ê³ ë„í™”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228f28ff",
   "metadata": {},
   "source": [
    "ì•ì—ì„œ ì „ì²˜ë¦¬í•œ ë°ì´í„°ë“¤ì„ ì´ìš©í•´ ëª¨ë¸ì„ í•™ìŠµí•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ëª©í‘œ: ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e83e552",
   "metadata": {},
   "source": [
    "### 1. ë°ì´í„° ë¶„ì„ ì „ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78084ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.option.mode.chained_assignement = None \n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.csv('sample_submission.csv')\n",
    "interest_rate = pd.read_csv('interest_rate.csv')\n",
    "\n",
    "train['train_test'] = 'train'\n",
    "test['train_test'] = 'test'\n",
    "all_data = pd.concat([train, test])\n",
    "all_data = all_data.reset_index(drop=True)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50cdec0",
   "metadata": {},
   "source": [
    "### 2. ê°€ê²© ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c089f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_int(string):\n",
    "    if type(string) == str:\n",
    "        string = string.replace(',','')\n",
    "        return int(string)\n",
    "    else:\n",
    "        return string\n",
    "all_data['transaction_real_price'] = all_data['transation_real_price'].apply(str_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75196a49",
   "metadata": {},
   "source": [
    "### 3. ë‚ ì§œ ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cde554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tran_date(x):\n",
    "    if type(x) == int:\n",
    "        if x < 10:\n",
    "            return '0'+str(x)\n",
    "        else:\n",
    "            return str(x)\n",
    "    else:\n",
    "        return x \n",
    "\n",
    "all_data['transaction_day'] = all_data['transaction_day'].apply(preprocess_tran_date)\n",
    "all_data['transaction_date'] = all_data['transaction_year_month'].astype(int).astype(str) + all_data['transaction_day'].astype(str)\n",
    "all_data['transaction_date'] = pd.to_datetime(all_data['transaction_date'])\n",
    "all_data = all_data.sort_values('transaction_date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bac6664",
   "metadata": {},
   "source": [
    "### 4. ìµœê·¼ì— ê±°ë˜ëœ ê°€ê²© êµ¬í•˜ê¸°\n",
    "ë¶€ë™ì‚°ì—ì„œ ì•„íŒŒíŠ¸ì˜ ì‹œì¥ ê°€ê²©ì„ í‰ê°€í•  ë•Œ, ìµœê·¼ì— ê±°ë˜ëœ ì•„íŒŒíŠ¸ì˜ ê°€ê²©ì„ ê¸°ì¤€ìœ¼ë¡œ ë§¤ë¬¼ì„ í‰ê°€í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.   \n",
    "  \n",
    "ê·¸ë ‡ê¸° ë•Œë¬¸ì— get_recent_price() í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ì„œ, ì•„íŒŒíŠ¸ì˜ ìµœê·¼ ê°€ê²©ì„ êµ¬í•´ ë´…ì‹œë‹¤.   \n",
    "ì•„íŒŒíŠ¸ì˜ ìµœê·¼ ê°€ê²©ì€ ì•„íŒŒíŠ¸ê°€ ê±°ë˜ëœ ê³¼ê±° ë°ì´í„°ì—ì„œ ì°¾ìŠµë‹ˆë‹¤.   \n",
    "  \n",
    "1. ì „ì²´ ë°ì´í„°ì—ì„œ, í˜„ì¬ ì¸ë±ìŠ¤ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí•œë‹¤.  \n",
    "2. ì¶”ì¶œí•œ ë°ì´í„°ì—ì„œ, ê±°ë˜ë‚ ì§œê°€ row ê¸°ì¤€ìœ¼ë¡œ ê³¼ê±°ì´ê³  ë¹„ìŠ·í•œ ë©´ì ì¸ ì•„íŒŒíŠ¸ ê±°ë˜ë¥¼ ì¶”ì¶œí•œë‹¤.  \n",
    "3. ë§Œì•½ ì¶”ì¶œí•œ ê²°ê³¼ê°€ ì—†ìœ¼ë©´, 2016-01-01 ì´ì „ ë°ì´í„°ì—ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•œë‹¤.  \n",
    "4. ì¶”ì¶œí•œ ë°ì´í„° ì¤‘, ê°™ì€ ì•„íŒŒíŠ¸ì¸ ê²½ìš° í•´ë‹¹ ê°’ì„ ì¶”ì¶œí•œë‹¤.  \n",
    "5. ë§Œì•½ ê°™ì€ ì´ë¦„ì˜ ì•„íŒŒíŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´, ê°™ì€ ì‹œêµ°êµ¬ì— ìˆëŠ” ì•„íŒŒíŠ¸ë¥¼ ì¶”ì¶œí•œë‹¤.  \n",
    "6. ë§Œì•½ ê°™ì€ ì‹œêµ¬êµ°ì— ì•„íŒŒíŠ¸ ê±°ë˜ë‚´ì—­ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´, ê°€ì¥ ìµœê·¼ ê±°ë˜ë¥¼ ì‚¬ìš©í•œë‹¤.  \n",
    "7. ê°€ì¥ ìµœê·¼ ê±°ë˜ê°€ ì—†ìœ¼ë©´ ì „ì²´ í‰ê· ì„ ì‚¬ìš©í•œë‹¤. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee41a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "def make_area_bucket(area):\n",
    "    if area < 60: # 59íƒ€ì…\n",
    "        return 0\n",
    "    elif area < 85: #84íƒ€ì…\n",
    "        return 1\n",
    "    else:\n",
    "        return 2 \n",
    "\n",
    "# ì•„íŒŒíŠ¸ ë©´ì  ì „ì²˜ë¦¬\n",
    "all_data['bucket_area'] = all_data['exclusive_use_area'].apply(make_area_bucket)\n",
    "\n",
    "# ì•„íŒŒíŠ¸ ì•„ì´ë”” ìƒì„±\n",
    "all_data['apartment_id'] = all_data.groupby(['sigungu', 'apt_name']).ngroup()\n",
    "\n",
    "def get_recent_price(all_data, idx, row):\n",
    "    # ì „ì²´ ë°ì´í„°ì—ì„œ, í˜„ì¬ ì´ì „ ì¸ë±ìŠ¤ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí•œë‹¤.\n",
    "    if idx >= 1:\n",
    "        index = idx -1\n",
    "    else:\n",
    "        index = idx\n",
    "\n",
    "    # ì „ì²´ ë°ì´í„°ì—ì„œ, í˜„ì¬ ì¸ë±ìŠ¤ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œ.\n",
    "    temp_df = all_data.loc[:index]\n",
    "\n",
    "    # ì¶”ì¶œí•œ ë°ì´í„°ì—ì„œ, ê±°ë˜ë‚ ì§œê°€ rowê¸°ì¤€ìœ¼ë¡œ ê³¼ê±°ì´ê³  ë¹„ìŠ·í•œ ë©´ì ì¸ ì•„íŒŒíŠ¸ ê±°ë˜ë¥¼ ì¶”ì¶œ.\n",
    "    tempt_df = temp_df[\n",
    "        (temp_df['transaction_date'] < row['transaction_date']) & \n",
    "        (temp_df['bucket_area'] == row['bucket_area'])\n",
    "    ]\n",
    "\n",
    "    # ë§Œì•½ ì¶”ì¶œí•œ ê²°ê³¼ê°€ ì•„ë¬´ê²ƒë„ ì—†ìœ¼ë©´, 2026-01-01 ì´ì „ ë°ì´í„°ì—ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œ. \n",
    "    if len(temp_df) == 0:\n",
    "        temp_df = all_data[\n",
    "            (all_data[''])\n",
    "        ]    \n",
    "    \n",
    "    # ì¶”ì¶œí•œ ë°ì´í„° ì¤‘, ê°™ì€ ì•„íŒŒíŠ¸ì¸ ê²½ìš° í•´ë‹¹ ê°’ì„ ì¶”ì¶œ.\n",
    "    recent_price = temp_df[(ttemp_df['apartment_id'] == row['apartment_id'])]\n",
    "\n",
    "    if len(recent_price) == 0:\n",
    "        # ë§Œì•½ ê°™ì€ ì´ë¦„ì˜ ì•„íŒŒíŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´, ê°™ì€ ì‹œêµ°ã„±êµ¬ì— ìˆëŠ” ì•„íŒŒíŠ¸ë¥¼ ì¶”ì¶œ.\n",
    "        recent_price = temp_df[(temp_df['sigungu'] == row['sigungu'])]\n",
    "        recent_price = recent_price.iloc[-1]['transaction_real_price'] \n",
    "    else:\n",
    "        # ë§Œì•½ ê°™ì€ ì‹œêµ°êµ¬ì— ì•„íŒŒíŠ¸ ê±°ë˜ë‚´ì—­ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´, ê°€ì¥ ìµœê·¼ ê±°ë˜ë¥¼ ì‚¬ìš©.\n",
    "        recent_price = recent_price.iloc[-1]['transaction_real_price']\n",
    "\n",
    "    # ê°€ì¥ ìµœê·¼ ê±°ë˜ê°€ ì—†ìœ¼ë©´ ì „ì²´ í‰ê· ì„ ì‚¬ìš©.\n",
    "    if recent_price is None:\n",
    "        recent_price = temp_df['transaction_real_price'].mean()\n",
    "    \n",
    "    return recent_price \n",
    "\n",
    "for idx, row in tqdm(all_data.iterrows(), total = all.data.shape[0]):\n",
    "    if row['train_test'] == 'test':\n",
    "        continue\n",
    "    all_data.loc[idx, 'recent_price'] = get_recent_price(all_data, idx, row) \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f8787e",
   "metadata": {},
   "source": [
    "### 5. ì•„íŒŒíŠ¸ ìµœê·¼ ê±°ë˜ëŸ‰ êµ¬í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27cab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "for idx, row in tqdm(all_data.iterrows(), total = all_data.shape[0]):\n",
    "    # transaction_dateê°€ 2014-03-30 ë‚ ì§œ ì´ì „ ë°ì´í„°ì¸ ê²½ìš°, 2014-03-30 ~ 2014-01-01 ë°ì´í„°ë¥¼ ì¶”ì¶œ.\n",
    "    if row['transaction_data'] <= datetime.strptime('2014-03-30', \"%Y-%m-%d\"):\n",
    "        start_day = datetime.strptime('2014-03-30', \"%Y-%m-%d\")\n",
    "        end_dat = datetime.strptime('2014-01-01', \"%Y-%m-%d\")\n",
    "        cnt = len(all_data[(all_data['transaction_date'] >= start_day) & (all_data['transaction_date'] < end_day) & (all_data['sigungu'] == row['sigungu'])])\n",
    "        \n",
    "    # ê±°ë˜ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ 3ê°œì›” ì´ì „ ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ ë´…ì‹œë‹¤.\n",
    "    else:\n",
    "        start_day = row['transaction_date'] - timedelta(days=90) \n",
    "        end_day = row['transaction_date']\n",
    "        cnt = len(all_data[(all_data['transaction_date'] >= start_day) & (all_data['transaction_date'] < end_day) & (all_data['sigungu'] == row['sigungu'])])\n",
    "        \n",
    "    all_data.loc[idx, 'transaction_cnt'] = cnt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84006e30",
   "metadata": {},
   "source": [
    "### 6. ê¸ˆë¦¬ ë°ì´í„° ì¶”ê°€í•˜ê¸°\n",
    "[ë¬¸ì œ1] Datetime ìœ í˜•ì¸ ë°ì´í„° 'transaction_date'ì—ì„œ 'year', 'month' ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918aaec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_date(row):\n",
    "    month_day = row['ì›”ì¼'].replace('ì›” ','-')\n",
    "    month_day = month_day.replace('ì¼', '')\n",
    "    date = str(row['ì—°ë„'])+ '-' + month_day \n",
    "    return date\n",
    "\n",
    "# ë‚ ì§œ ë°ì´í„° yyyy-mm-dd í˜•íƒœë¡œ ë³€ê²½\n",
    "interest_rate['ë‚ ì§œ'] = interest_rate.applt(lambda x: make_date(x), axis=1) \n",
    "\n",
    "# ë‚ ì§œë¥¼ datetime ìœ í˜•ìœ¼ë¡œ ë³€ê²½\n",
    "interest_rate['ë‚ ì§œ'] = pd.to_datetime(interest_rate['ë‚ ì§œ'])\n",
    "\n",
    "for idx, row in tqdm(all_data.iterrow(), total = all_data.shape[0]):\n",
    "    date = row['transaction_date']\n",
    "    rate = interest_rate[interest_rate['ë‚ ì§œ'] <= date].oloc[0]['ê¸ˆë¦¬']\n",
    "    all_data.loc[idx, 'interest_rate'] = rate\n",
    "\n",
    "# ì—°ì›” ë°ì´í„° ì¶”ê°€\n",
    "all_data['transaction_year'] = all_data['transaction_date'].year # ë°˜ë“œì‹œ .dt.year  # datetimeì€ DataFrameì´ ì•„ë‹ˆë¼ ìë£Œí˜•(type)ì´ë¼ .dt ì—†ì´ ì¸ë±ì‹± ë¶ˆê°€ \n",
    "all_data['transaction_month'] = all_data['transaction_date'].month # .dt.month ë¡œ ì¶œë ¥.  # ë©”ì„œë“œ í•¨ìˆ˜ê°€ ì•„ë‹Œ ì†ì„±ì´ê¸° ë•Œë¬¸ì— () ìƒëµ ! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cbc2e1",
   "metadata": {},
   "source": [
    "### 7. ì•„íŒŒíŠ¸ ì´ë¦„ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "[ë¬¸ì œ2] ë¹ˆì¹¸ì„ ì±„ì›Œ ê°€ê²©ì„ ê¸°ì¤€ìœ¼ë¡œ K-means í´ëŸ¬ìŠ¤í„°ë§ì„ ì´ìš©í•´ ì•„íŒŒíŠ¸ë¥¼ êµ°ì§‘í™”í•´ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b8f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np \n",
    "\n",
    "# ì•„íŒŒíŠ¸ ë³„ë¡œ ê°€ê²© í‰ê· ê°’ êµ¬í•˜ê¸°\n",
    "train = all_data[all_data['train_test'] == 'train']\n",
    "data = train[['apt_name', 'transaction_real_price']]\n",
    "\n",
    "data = data.groupby('apt_name').mean()\n",
    "arr = data['transaction_real_price'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "# ê°€ê²©ì„ ê¸°ì¤€ìœ¼ë¡œ ì•„íŒŒíŠ¸ êµ°ì§‘í™”\n",
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k, n_init=10)\n",
    "kmeans.fit(arr)\n",
    "\n",
    "# ê°€ê²©ì„ ê¸°ì¤€ìœ¼ë¡œ êµ°ì§‘ì˜ ìˆœì„œë¥¼ ì •ë ¬í•˜ê¸° ìœ„í•´ ì¸ë±ìŠ¤ë¥¼ ì¶”ì¶œ \n",
    "sort_order = np.argsort(kmeans.cluster_centers.flatten())\n",
    "\n",
    "# êµ°ì§‘í™” ê²°ê³¼ë¥¼ ê°€ê²© ìˆœì„œëŒ€ë¡œ ì¬í• ë‹¹\n",
    "labels = np.zeros_like(kmeans.labels_)\n",
    "for i, cluster in enumerate(sort_order):\n",
    "    labels[kmeans.labels_ == cluster] = i\n",
    "    \n",
    "# êµ°ì§‘í™” ê²°ê³¼ì™€ ê°€ê²©ì„ ë°ì´í„°ì— ì¶”ê°€\n",
    "data['cluster'] = labels\n",
    "data = data.reset_index()\n",
    "data = data[['apt_name', 'cluster']]\n",
    "\n",
    "all_data = pd.merge(all_data, data, how='left', left_on='apt_name', right_on='apt_name')\n",
    "\n",
    "cluster_mode = all_data.loc[all_data['train_test'] == 'train', 'cluster'].mode()[0]\n",
    "all_data['cluster'] = all_data['cluster'].fillna(cluster_mode)\n",
    "\n",
    "all_data['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8469ee",
   "metadata": {},
   "source": [
    "## 8. ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í•™ìŠµ\n",
    "[ë¬¸ì œ3] objective ë©”ì†Œë“œ ì´ìš©í•´ ì˜µíŠœë‚˜ ì‹¤í–‰ ë‚´ìš©ì„ ì •ì˜í•˜ê³ , ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì•„ ë´…ì‹œë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d25d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna \n",
    "\n",
    "validation_year = 2022 \n",
    "\n",
    "columns = [\n",
    "    'recent_price', 'transaction_cnt', 'interest_rate', 'transaction_year', 'transaction_month', 'cluster'\n",
    "]\n",
    "\n",
    "train_x = all_data.loc[(all_data['train_test'] == 'train') & (all_data['transaction_year'] < validation_year), columns]\n",
    "train_y = all_data.loc[(all_data['train_test'] == 'train') & (all_data['transaction_year'] < validation_year), 'transaction_real_price']\n",
    "\n",
    "val_x = all_data.loc[(all_data['train_test'] == 'train') & (all_data['transaction_year'] == validation_year), columns]\n",
    "val_y = all_data.loc[(all_data['train_test'] == 'train') & (all_data['transaction_year'] == validation_year, 'transaction_real_price']\n",
    "                     \n",
    "def objective(trial):\n",
    "    # í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ëŒ€ìƒ\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 100)\n",
    "    max_depth = trial.suggest_int('mac_dapth', 2, 32)\n",
    "    \n",
    "    # ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í•™ìŠµ\n",
    "    model = RandomForestRegressor(n_estimators, max_deppth=max_depth, random_state=7)\n",
    "    model.fit(train_x, train_y) \n",
    "    \n",
    "    # ê²€ì¦ ë°ì´í„°ë¡œ í‰ê°€\n",
    "    y_pred = model.predict(val_x)\n",
    "    mse = mean_squared_error(vla_y, y_pred)\n",
    "    return mse \n",
    "    \n",
    "# Optunaë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_params_rf = study.best_params\n",
    "print(\"Best Params:\", best_params_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933dc558",
   "metadata": {},
   "source": [
    "### 9. Xgboost ëª¨ë¸ í•™ìŠµ\n",
    "[ë¬¸ì œ4]\n",
    "ì˜ˆì¸¡ë¬¸ì œì— ì‚¬ìš©í•˜ëŠ” xgboost ëª¨ë¸ì„ ë§Œë“¤ì–´ ë´…ì‹œë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea36337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "def objective(trial):\n",
    "    # í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ëŒ€ìƒ\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 100)\n",
    "    max_depth = trial.sugget_int('max_depth', 2, 32)\n",
    "    learning_rate = trial.suggest_loungeform('learning_rate', 0.001, 0.1)\n",
    "    \n",
    "    # xgboost ëª¨ë¸ í•™ìŠµ\n",
    "    model = xgb.XGBRegressor(n_estimators=n_estimators,\n",
    "                             max_depth=max_dapth,\n",
    "                             learning_rate = learning_rate,\n",
    "                             random_state=7)\n",
    "    model.fit(train_x, train_y)\n",
    "    \n",
    "    # ê²€ì¦ ë°ì´í„°ë¡œ í‰ê°€ \n",
    "    y_pred = model.predict(val_x)\n",
    "    mse = mean_squared_error(val_y, y_pred)\n",
    "    return mse\n",
    "\n",
    "# Optunaë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_params_xgb =study.best_params \n",
    "print(\"Best Params:\", best_params_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ee6e41",
   "metadata": {},
   "source": [
    "## 10. ëª¨ë¸ êµì°¨ê²€ì¦\n",
    "[ë¬¸ì œ5] ëœë¤í¬ë ˆìŠ¤íŠ¸ì˜ ì˜ˆì¸¡ê°’ê³¼ XGBoostì˜ ì˜ˆì¸¡ê°’ì˜ í‰ê· ì„ êµ¬í•´ ì˜ˆì¸¡ê°’ì„ ê³„ì‚°í•´ ë´…ì‹œë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63511205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "for validation_year in [2018, 2019, 2020, 2021, 2022]\n",
    "columns = [\n",
    "    'recent_price', 'transaction_cnt', 'interest_rate', 'transaction_year', 'transaction_month', 'cluster',\n",
    "]\n",
    "train_x = all_data.loc[(all_data['train_test'] == 'train') & (all_data['transaction_year'] < validation_year), columns]\n",
    "train_y = all_data.loc[(all_data['train_test'] == 'train') & (all_data['transaction_year'] < validation_year), 'transaction_real_price']\n",
    "\n",
    "val_x = all_data.loc[(all_data['train_test'] == 'train') & (all_data['transaction_year'] == validation_year), columns]\n",
    "val_y = all_data.loc[(all_data['train_test'] == 'train') & (all_data['transaction_year'] == validation_year), 'transaction_real_price'] \n",
    "\n",
    "# ëª¨ë¸ ìƒì„± ë° í›ˆë ¨\n",
    "model_rf = RandomForestRegressor(n_estimators=best_params_rf['n_estimators'], \n",
    "                                 max_depth=best_params_rf['max_depth'],\n",
    "                                 random_state=7\n",
    "                                 )\n",
    "model_rf.fit(train_x, train_y)\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(n_estimators=best_params_xgb['n_estimators'], \n",
    "                             max_depth=best_params_xgb['max_depth'],\n",
    "                             learning_rate=best_params_xgb['learning_rate'],\n",
    "                             random_state=7)\n",
    "\n",
    "model_xgb.fit(train_x, train_y)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "pred_rf_ls = model_rf.predict(val_x)\n",
    "pred_xgb_ls = model_xgb.predict(val_x)\n",
    "blended_prediction = (pred_rf_ls + pred_xgb_ls) /2 \n",
    "\n",
    "mae = mean_absolute_error(blended_prediction, val_y)\n",
    "print(validation_year, 'ë…„ë„ MAE:' , mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d41db",
   "metadata": {},
   "source": [
    "## 11. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡\n",
    "[ë¬¸ì œ6] ë¹ˆì¹¸ì„ ì±„ì›Œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58852d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "columns = [\n",
    "    'recent_price', 'transaction_cnt', 'interest_rate', 'transaction_year', 'transaction_month', 'cluste', \n",
    "]\n",
    "train_x = all_data.loc[all_data['train_test'] == 'train', columns]\n",
    "train_y = all_data.loc[all_data['train_test'] == 'train', 'transaction_real_price'] \n",
    "test_x = all_data.loc[all_data['train_test'] == 'test', columns] \n",
    "\n",
    "# ëª¨ë¸ ìƒì„± ë° í›ˆë ¨\n",
    "model_rf = RandomForestRegressor(n_estimators=best_params_rf['n_estimators'],\n",
    "                                 max_depth=best_params_rf['max_depth'],\n",
    "                                 random_state=7\n",
    "                                )  \n",
    "model_rf.fit(train_x, train_y)\n",
    "\n",
    "model_xgb = xgb.XGBRgressor(n_estimators=best_params_xgb['n_estimators'],\n",
    "                            max_depth=best_params_xgb['max_depth'],\n",
    "                            learning_rate=best_params_xgb['learning_rate'],\n",
    "                            random_state=7)\n",
    "model_xgb.fit(train_x, train_y)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "pred_ls = list()\n",
    "now_df = all_data.loc[all_data['train_test'] == 'train']\n",
    "test = all_data.loc[all_data['train_test'] == 'test']\n",
    "\n",
    "for idx, row in tqdm(test.iterrows(), total = test.shape[0]):\n",
    "    now_df = pd.concat([now_df, test.loc[[idx]]]) \n",
    "    test_x.loc[idx, 'rescent_price'] = get_recent_price(now_df, idx, row)\n",
    "    \n",
    "    # ì˜ˆì¸¡\n",
    "    pred_rf_ls = model_rf.predict(test_x.loc[idx:idx])\n",
    "    pred_xgb_ls = model_xgb.predict(test_x.loc[idx:idx])\n",
    "    blended_prediction = (pred_rf_ls + pred_xgb_ls) / 2\n",
    "    \n",
    "    now_df.loc[idx, 'transaction_real_price'] = blended_prediction\n",
    "    pred_ls.append(blended_prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d003291b",
   "metadata": {},
   "source": [
    "## 12. ì •ë‹µ ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "[ë¬¸ì œ7] ì˜ˆì¸¡í•œ ê²°ê³¼ê°€ ë“¤ì–´ìˆëŠ” pred_lsë¥¼ submission['transaction_real_price']ì— ë„£ì–´ì£¼ì„¸ìš”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7800718",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['transaction_real_price'] = pred_ls\n",
    "submission.to_csv('submission.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0a78ad",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
